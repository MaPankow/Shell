2023-05-24 15:02:55,828 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/eu-korruption-massnahmen-ethik-gremium-zweifel-1.5878780 -> https://www.sueddeutsche.de/politik/eu-korruption-massnahmen-ethik-gremium-zweifel-1.5878780?reduced=true
2023-05-24 15:02:56,812 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 76, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 15:02:57,109 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/bayern/bayern-mint-berufe-frauen-maenner-geschlechtergerechtigkeit-1.5878910 -> https://www.sueddeutsche.de/bayern/bayern-mint-berufe-frauen-maenner-geschlechtergerechtigkeit-1.5878910?reduced=true
2023-05-24 15:02:57,113 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/israel-staatshaushalt-netanjahu-ultraorthodoxe-1.5879030 -> https://www.sueddeutsche.de/politik/israel-staatshaushalt-netanjahu-ultraorthodoxe-1.5879030?reduced=true
2023-05-24 15:03:04,794 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/ausland/2023-05/griechenland-neuwahlen-mitsotakis-tsipras -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fausland%2F2023-05%2Fgriechenland-neuwahlen-mitsotakis-tsipras
2023-05-24 15:03:04,796 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/fdp-fraktion-wasserstoff-als-energietraeger-staerker-foerdern -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Ffdp-fraktion-wasserstoff-als-energietraeger-staerker-foerdern
2023-05-24 15:03:04,798 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/deutschland/2023-05/gesetz-digitalisierung-verwaltung-buergerkonto -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fdeutschland%2F2023-05%2Fgesetz-digitalisierung-verwaltung-buergerkonto
2023-05-24 15:03:04,799 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/sport/2023-05/mats-hummels-borussia-dortmund-fussballpodcast -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fsport%2F2023-05%2Fmats-hummels-borussia-dortmund-fussballpodcast
2023-05-24 15:03:04,799 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/geschlossene-schule-ministerium-weist-vorwuerfe-zurueck -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fgeschlossene-schule-ministerium-weist-vorwuerfe-zurueck
2023-05-24 15:03:04,802 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/bundesnetzagentur-praesident-begruesst-wasserstoff-beschluss -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fbundesnetzagentur-praesident-begruesst-wasserstoff-beschluss
2023-05-24 15:03:04,812 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/deutschland/2023-05/robert-habeck-transparenz-personalpolitik-bundestag-befragung -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fdeutschland%2F2023-05%2Frobert-habeck-transparenz-personalpolitik-bundestag-befragung
2023-05-24 15:03:04,816 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/lina-e-mein-letztes-wort-soll-danke-sein -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Flina-e-mein-letztes-wort-soll-danke-sein
2023-05-24 15:03:04,816 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/ausland/2023-05/stichwahl-tuerkei-recep-tayyip-erdogan-kemal-kilicdaroglu-haeufigste-fragen-faq -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fausland%2F2023-05%2Fstichwahl-tuerkei-recep-tayyip-erdogan-kemal-kilicdaroglu-haeufigste-fragen-faq
2023-05-24 15:03:04,827 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/kissinger-schuld-an-ukraine-krieg-nicht-bei-russland-allein -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fkissinger-schuld-an-ukraine-krieg-nicht-bei-russland-allein
2023-05-24 15:03:04,933 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/juwelendiebstahl-aus-gruenem-gewoelbe-revision-eingelegt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fjuwelendiebstahl-aus-gruenem-gewoelbe-revision-eingelegt
2023-05-24 15:03:04,936 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/bad-hersfelder-festspiele-2022-mit-defizit-von-187-000-euro -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fbad-hersfelder-festspiele-2022-mit-defizit-von-187-000-euro
2023-05-24 15:03:04,938 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/letzte-generation-durchsuchungen-auch-im-norden -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fletzte-generation-durchsuchungen-auch-im-norden
2023-05-24 15:03:04,938 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/wes-anderson-erfreut-cannes-mit-grossem-star-aufgebot -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fwes-anderson-erfreut-cannes-mit-grossem-star-aufgebot
2023-05-24 15:03:04,938 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/komiker-hermanns-von-berlin-aus-scheint-hamburg-verlockend -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fkomiker-hermanns-von-berlin-aus-scheint-hamburg-verlockend
2023-05-24 15:03:05,803 - root - INFO - Got redirected 1 time(s) from https://www.tagesschau.de/ausland/amerika/11km-podcast-usa-einwanderungspolitik-100.html -> https://www.ardaudiothek.de/sendung/11km-der-tagesschau-podcast/12200383/
2023-05-24 15:03:07,447 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/investoren-für-die-fußball-bundesliga/a-65708519?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/investoren-fuer-die-fussball-bundesliga/a-65708519?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 15:03:07,957 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/wettskandal-wirft-dunkle-schatten-über-brasiliens-fußball/a-65706538?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/wettskandal-wirft-dunkle-schatten-ueber-brasiliens-fussball/a-65706538?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 15:03:07,962 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/fc-bayern-münchen-steckt-in-der-krise/a-65696062?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/fc-bayern-muenchen-steckt-in-der-krise/a-65696062?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 15:03:08,283 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/160-jahre-spd-k-ein-grund-zum-feiern/a-65676944?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/160-jahre-spd-kein-grund-zum-feiern/a-65676944?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 15:03:08,727 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/cannes-2023-highlights-der-ersten-tage/a-65677019?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/cannes-2023-filme-roter-teppich/a-65677019?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 15:03:26,026 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/schleswig-holstein/Hallig-Suedfall-Kirche-von-versunkenem-Handelsplatz-Rungholt-entdeckt,rungholt148.html -> https://www.ndr.de/nachrichten/schleswig-holstein/Rungholt-Kirche-von-versunkenem-Handelsplatz-vor-Hallig-Suedfall-entdeckt,rungholt148.html
2023-05-24 15:03:28,076 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/niedersachsen/Unfall-in-Bad-Harzburg-88-Jaehrige-faehrt-vor-Schule-in-Menschengruppe,unfall17708.html -> https://www.ndr.de/nachrichten/niedersachsen/Bad-Harzburg-88-Jaehrige-erfasst-vor-Schule-mehrere-Menschen,unfall17708.html
2023-05-24 16:54:33,880 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/janet-yellen-us-schuldenstreit-schuldenobergrenze-zahlungsausfall -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fjanet-yellen-us-schuldenstreit-schuldenobergrenze-zahlungsausfall
2023-05-24 16:54:33,896 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/lebensgeschichte -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Flebensgeschichte
2023-05-24 16:54:33,918 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/eierproduktion-huhn-legevorgang -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Feierproduktion-huhn-legevorgang
2023-05-24 16:54:33,919 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/gti-treffen-vw-golf-woerthersee-wolfsburg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fgti-treffen-vw-golf-woerthersee-wolfsburg
2023-05-24 16:54:33,927 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/unheilbare-erbkrankheit-huntington-umgang-wendepunkt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Funheilbare-erbkrankheit-huntington-umgang-wendepunkt
2023-05-24 16:54:33,934 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/ampel-koalition-streit-heizungsgesetz-geg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fampel-koalition-streit-heizungsgesetz-geg
2023-05-24 16:54:33,934 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/fitnessstudio-lifestyle-vereinssport-pruefers-toechter -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Ffitnessstudio-lifestyle-vereinssport-pruefers-toechter
2023-05-24 16:54:33,951 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/fc-bayern-muenchen-krise-fussball -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Ffc-bayern-muenchen-krise-fussball
2023-05-24 16:54:33,951 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/harald-martenstein-prinz-harry-kroenung-koenig-charles-iii -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Fharald-martenstein-prinz-harry-kroenung-koenig-charles-iii
2023-05-24 16:54:33,953 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/ns-zeitzeugen-kz-theresienstadt-zweiter-weltkrieg-nationalsozialismus -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Fns-zeitzeugen-kz-theresienstadt-zweiter-weltkrieg-nationalsozialismus
2023-05-24 16:54:34,054 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/t-c-boyle-ratschlaege-leben -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Ft-c-boyle-ratschlaege-leben
2023-05-24 16:54:34,060 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/erderwaermung-klimakrise-temperaturanstieg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Ferderwaermung-klimakrise-temperaturanstieg
2023-05-24 16:54:34,064 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/ungarn-viktor-orban-menschenschlepper-freilassung -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fungarn-viktor-orban-menschenschlepper-freilassung
2023-05-24 16:54:34,064 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/fussball-wm-frauen-tv-rechte-ard-zdf-fifa -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Ffussball-wm-frauen-tv-rechte-ard-zdf-fifa
2023-05-24 16:54:34,082 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/spielplatz-architektur-design-ole-barslund-nielsen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fspielplatz-architektur-design-ole-barslund-nielsen
2023-05-24 16:54:40,861 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/janet-yellen-us-schuldenstreit-schuldenobergrenze-zahlungsausfall -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fjanet-yellen-us-schuldenstreit-schuldenobergrenze-zahlungsausfall
2023-05-24 16:54:40,876 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/gti-treffen-vw-golf-woerthersee-wolfsburg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fgti-treffen-vw-golf-woerthersee-wolfsburg
2023-05-24 16:54:40,899 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/eierproduktion-huhn-legevorgang -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Feierproduktion-huhn-legevorgang
2023-05-24 16:54:40,911 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/unheilbare-erbkrankheit-huntington-umgang-wendepunkt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Funheilbare-erbkrankheit-huntington-umgang-wendepunkt
2023-05-24 16:54:40,924 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/ns-zeitzeugen-kz-theresienstadt-zweiter-weltkrieg-nationalsozialismus -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Fns-zeitzeugen-kz-theresienstadt-zweiter-weltkrieg-nationalsozialismus
2023-05-24 16:54:40,947 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/lebensgeschichte -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Flebensgeschichte
2023-05-24 16:54:40,952 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/fitnessstudio-lifestyle-vereinssport-pruefers-toechter -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Ffitnessstudio-lifestyle-vereinssport-pruefers-toechter
2023-05-24 16:54:40,968 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/fc-bayern-muenchen-krise-fussball -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Ffc-bayern-muenchen-krise-fussball
2023-05-24 16:54:40,969 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/ampel-koalition-streit-heizungsgesetz-geg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fampel-koalition-streit-heizungsgesetz-geg
2023-05-24 16:54:40,969 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/harald-martenstein-prinz-harry-kroenung-koenig-charles-iii -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Fharald-martenstein-prinz-harry-kroenung-koenig-charles-iii
2023-05-24 16:54:41,091 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/ungarn-viktor-orban-menschenschlepper-freilassung -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fungarn-viktor-orban-menschenschlepper-freilassung
2023-05-24 16:54:41,092 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/zeit-magazin/2023/22/t-c-boyle-ratschlaege-leben -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fzeit-magazin%2F2023%2F22%2Ft-c-boyle-ratschlaege-leben
2023-05-24 16:54:41,096 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/erderwaermung-klimakrise-temperaturanstieg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Ferderwaermung-klimakrise-temperaturanstieg
2023-05-24 16:54:41,096 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/spielplatz-architektur-design-ole-barslund-nielsen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fspielplatz-architektur-design-ole-barslund-nielsen
2023-05-24 16:54:41,097 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/fussball-wm-frauen-tv-rechte-ard-zdf-fifa -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Ffussball-wm-frauen-tv-rechte-ard-zdf-fifa
2023-05-24 16:58:53,676 - fundus_crash_2023-05-24 16:58:53.674134 - ERROR - name 'BZCrawler' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database(backend_session, backup_session)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 35, in crawl_to_database
    original_crawlers = instantiate_all_crawlers()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/__init__.py", line 24, in instantiate_all_crawlers
    BZCrawler(),
NameError: name 'BZCrawler' is not defined
2023-05-24 16:59:03,447 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/britische-royals-wollen-sterbliche-ueberreste-eines-aethiopischen-prinzen-nicht-zurueckgeben-li.351798 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/britische-royals-wollen-sterbliche-ueberreste-eines-aethiopischen-prinzen-nicht-zurueckgeben-li.351798
2023-05-24 16:59:03,449 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/rache-fuer-blockade-beim-heizgesetz-fdp-wirft-gruenen-vor-hilfe-im-ahrtal-zu-verzoegern-li.351689 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/rache-fuer-blockade-beim-heizgesetz-fdp-wirft-gruenen-vor-hilfe-im-ahrtal-zu-verzoegern-li.351689
2023-05-24 16:59:03,451 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/union-fraktion-will-haeufigeres-singen-der-nationalhymne-und-mehr-deutschlandfahnen-patriotismus-li.351786 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/union-fraktion-will-haeufigeres-singen-der-nationalhymne-und-mehr-deutschlandfahnen-patriotismus-li.351786
2023-05-24 16:59:03,451 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/wenn-der-sohn-ploetzlich-geld-braucht-bka-warnt-vor-betruegerischen-schockanrufen-telefon-betrugsmasche-hilfe-weisser-ring-li.351742 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/wenn-der-sohn-ploetzlich-geld-braucht-bka-warnt-vor-betruegerischen-schockanrufen-telefon-betrugsmasche-hilfe-weisser-ring-li.351742
2023-05-24 16:59:03,452 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/amsterdam-niederlande-verbietet-kiffen-cannabis-im-alten-zentrum-massnahme-gegen-tourismus-li.351774 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/amsterdam-niederlande-verbietet-kiffen-cannabis-im-alten-zentrum-massnahme-gegen-tourismus-li.351774
2023-05-24 16:59:03,453 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/umsturzplaene-der-vereinten-patrioten-angeklagter-erklaert-sich-vor-gericht-li.351785 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/umsturzplaene-der-vereinten-patrioten-angeklagter-erklaert-sich-vor-gericht-li.351785
2023-05-24 16:59:03,454 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/die-mauer-asisi-panorama-berlin-tickets-xqz-li.314937 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/die-mauer-asisi-panorama-berlin-tickets-xqz-li.314937
2023-05-24 16:59:03,455 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/kinderpornographie-erschreckend-was-die-behoerden-alles-nicht-wissen-li.351396 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/kinderpornographie-erschreckend-was-die-behoerden-alles-nicht-wissen-li.351396
2023-05-24 16:59:03,455 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/waermewende-neues-heizungsgesetz-von-robert-habeck-im-wortlaut-li.351755 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/waermewende-neues-heizungsgesetz-von-robert-habeck-im-wortlaut-li.351755
2023-05-24 16:59:03,456 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/wie-wichtig-ist-bachmut-fuer-den-sieg-russlands-in-der-ukraine-li.351683 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/wie-wichtig-ist-bachmut-fuer-den-sieg-russlands-in-der-ukraine-li.351683
2023-05-24 16:59:03,584 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/literatur/daniel-hoera-es-gab-so-viele-verbrechen-in-berlin-dass-niemand-genau-hinsah-li.351011 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/literatur/daniel-hoera-es-gab-so-viele-verbrechen-in-berlin-dass-niemand-genau-hinsah-li.351011
2023-05-24 16:59:03,585 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/video-im-klassenchat-maedchen-heimlich-in-berliner-fitnessstudio-gefilmt-li.351720 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/video-im-klassenchat-maedchen-heimlich-in-berliner-fitnessstudio-gefilmt-li.351720
2023-05-24 16:59:03,586 - root - WARNING - Skipped https://www.berliner-zeitung.de/panorama/arno-duebel-ist-tot-so-wurde-er-zu-deutschlands-beruehmtestem-arbeitslosen-li.351679 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/panorama/arno-duebel-ist-tot-so-wurde-er-zu-deutschlands-beruehmtestem-arbeitslosen-li.351679
2023-05-24 16:59:03,587 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/stadtrallye-berlin-schulklassen-klassenfahrt-schnitzeljagd-tickets-xqz-li.351042 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/stadtrallye-berlin-schulklassen-klassenfahrt-schnitzeljagd-tickets-xqz-li.351042
2023-05-24 16:59:03,587 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/dicke-rauchwolke-steigt-ueber-der-krim-bruecke-auf-militaeruebung-li.351736 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/dicke-rauchwolke-steigt-ueber-der-krim-bruecke-auf-militaeruebung-li.351736
2023-05-24 16:59:03,607 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-marzahn-allee-der-kosmonauten-mann-antisemitisch-beleidigt-und-angegriffen-li.351732 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-marzahn-allee-der-kosmonauten-mann-antisemitisch-beleidigt-und-angegriffen-li.351732
2023-05-24 16:59:03,608 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-charlottenburg-unfall-fussgaenger-tritt-auf-den-radweg-und-wird-verletzt-li.351710 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-charlottenburg-unfall-fussgaenger-tritt-auf-den-radweg-und-wird-verletzt-li.351710
2023-05-24 16:59:03,609 - root - WARNING - Skipped https://www.berliner-zeitung.de/gesundheit-oekologie/leide-ich-an-hyperempathie-wenn-ich-klimaklebern-ein-sponsorenkleben-empfehle-li.351043 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/gesundheit-oekologie/leide-ich-an-hyperempathie-wenn-ich-klimaklebern-ein-sponsorenkleben-empfehle-li.351043
2023-05-24 16:59:03,610 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/diw-studie-umfrage-mehrheit-der-deutschen-fuer-bedingungsloses-grundeinkommen-von-1200-euro-li.351714 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/diw-studie-umfrage-mehrheit-der-deutschen-fuer-bedingungsloses-grundeinkommen-von-1200-euro-li.351714
2023-05-24 16:59:03,632 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-tempelhof-polizei-muss-waschbaeren-aus-bvg-bus-entfernen-li.351703 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-tempelhof-polizei-muss-waschbaeren-aus-bvg-bus-entfernen-li.351703
2023-05-24 16:59:03,749 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-lichtenberg-rummelsburg-mann-sprueht-graffiti-an-kirche-festnahme-li.351698 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-lichtenberg-rummelsburg-mann-sprueht-graffiti-an-kirche-festnahme-li.351698
2023-05-24 16:59:03,754 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/nach-evakuierung-deutscher-botschaft-600-sudanesen-ohne-paesse-li.351684 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/nach-evakuierung-deutscher-botschaft-600-sudanesen-ohne-paesse-li.351684
2023-05-24 16:59:03,765 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/armageddon-der-weltwirtschaft-streit-um-usa-schuldenobergrenze-ist-oekonomischer-unsinn-li.351293 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/armageddon-der-weltwirtschaft-streit-um-usa-schuldenobergrenze-ist-oekonomischer-unsinn-li.351293
2023-05-24 16:59:03,765 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/nach-vatertagsparty-verschwunden-polizei-findet-leiche-von-vermisstem-22-jaehrigem-in-wentowsee-brandenburg-li.351676 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/nach-vatertagsparty-verschwunden-polizei-findet-leiche-von-vermisstem-22-jaehrigem-in-wentowsee-brandenburg-li.351676
2023-05-24 16:59:03,766 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/usa-militaerfahrzeuge-offenbar-fuer-angriff-auf-belgorod-russland-grenzregion-genutzt-li.351682 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/usa-militaerfahrzeuge-offenbar-fuer-angriff-auf-belgorod-russland-grenzregion-genutzt-li.351682
2023-05-24 16:59:03,767 - root - WARNING - Skipped https://www.berliner-zeitung.de/gesundheit-oekologie/wellness-ratgeber-gesund-schlafen-wann-muss-ich-ins-bett-gehen-berliner-forscher-bestimmen-persoenliche-innere-uhr-li.351301 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/gesundheit-oekologie/wellness-ratgeber-gesund-schlafen-wann-muss-ich-ins-bett-gehen-berliner-forscher-bestimmen-persoenliche-innere-uhr-li.351301
2023-05-24 16:59:03,769 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/ukrainische-kampfjet-koalition-luftwaffen-inspekteur-ingo-gerhartz-schliesst-deutsche-beteiligung-nicht-aus-li.351663 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/ukrainische-kampfjet-koalition-luftwaffen-inspekteur-ingo-gerhartz-schliesst-deutsche-beteiligung-nicht-aus-li.351663
2023-05-24 16:59:03,771 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/nato-uebung-us-militaerfahrzeuge-fahren-auf-autobahn-a4-bei-dresden-li.351670 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/nato-uebung-us-militaerfahrzeuge-fahren-auf-autobahn-a4-bei-dresden-li.351670
2023-05-24 16:59:03,772 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/hitlergruss-bei-konzert-gezeigt-anklage-gegen-ballermann-saengerin-melanie-mueller-li.351696 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/hitlergruss-bei-konzert-gezeigt-anklage-gegen-ballermann-saengerin-melanie-mueller-li.351696
2023-05-24 16:59:03,775 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/falschmeldung-gesundheitsminister-karl-lauterbach-dementiert-bild-bericht-zu-klinik-schliessungen-wegen-krankenhausreform-li.351645 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/falschmeldung-gesundheitsminister-karl-lauterbach-dementiert-bild-bericht-zu-klinik-schliessungen-wegen-krankenhausreform-li.351645
2023-05-24 16:59:03,910 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/london-zahl-russischer-deserteure-ist-deutlich-gestiegen-li.351646 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/london-zahl-russischer-deserteure-ist-deutlich-gestiegen-li.351646
2023-05-24 16:59:03,914 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/kommunale-versorger-warnen-trinkwasserpreise-koennen-fuer-verbraucher-steigen-li.351650 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/kommunale-versorger-warnen-trinkwasserpreise-koennen-fuer-verbraucher-steigen-li.351650
2023-05-24 16:59:03,914 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/live-bei-elon-musk-ron-desantis-will-am-mittwoch-bei-twitter-praesidentschaftskandidatur-gegen-donald-trump-verkuenden-li.351561 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/live-bei-elon-musk-ron-desantis-will-am-mittwoch-bei-twitter-praesidentschaftskandidatur-gegen-donald-trump-verkuenden-li.351561
2023-05-24 16:59:03,915 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/ampel-streit-heizungsgesetz-fdp-sieht-keine-eile-vor-der-sommerpause-spd-haelt-dagegen-li.351625 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/ampel-streit-heizungsgesetz-fdp-sieht-keine-eile-vor-der-sommerpause-spd-haelt-dagegen-li.351625
2023-05-24 16:59:03,917 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/studie-kinder-mit-behinderung-koennen-80-prozent-der-spielplaetze-nicht-nutzen-li.351628 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/studie-kinder-mit-behinderung-koennen-80-prozent-der-spielplaetze-nicht-nutzen-li.351628
2023-05-24 16:59:03,917 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/fahrer-hinterlaesst-spur-der-verwuestung-bei-angeblicher-parkplatzsuche-unfall-in-schnellerstrasse-in-niederschoeneweide-li.351629 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/fahrer-hinterlaesst-spur-der-verwuestung-bei-angeblicher-parkplatzsuche-unfall-in-schnellerstrasse-in-niederschoeneweide-li.351629
2023-05-24 16:59:03,925 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/die-fdp-und-die-waermepumpe-manchmal-kann-eine-blockade-auch-sinnvoll-sein-li.351303 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/die-fdp-und-die-waermepumpe-manchmal-kann-eine-blockade-auch-sinnvoll-sein-li.351303
2023-05-24 16:59:03,926 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/bundesregierung-49-euro-ticket-deutschlandticket-soll-sozialer-und-familienfreundlicher-werden-mitnahme-von-kindern-studententicket-li.351621 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/bundesregierung-49-euro-ticket-deutschlandticket-soll-sozialer-und-familienfreundlicher-werden-mitnahme-von-kindern-studententicket-li.351621
2023-05-24 16:59:03,932 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/bundesweite-razzia-gegen-letzte-generation-polizei-bayerisches-lka-klimaaktivisten-li.351637 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/bundesweite-razzia-gegen-letzte-generation-polizei-bayerisches-lka-klimaaktivisten-li.351637
2023-05-24 16:59:03,937 - root - WARNING - Skipped https://www.berliner-zeitung.de/mensch-metropole/friedrichstrasse-verkehrssenatorin-votiert-fuers-auto-hoffentlich-nur-diesmal-li.351454 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/mensch-metropole/friedrichstrasse-verkehrssenatorin-votiert-fuers-auto-hoffentlich-nur-diesmal-li.351454
2023-05-24 16:59:04,064 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/1-fc-union-berlin/1-fc-union-berlin-lieber-fussballgott-sei-noch-einmal-mit-haut-haar-und-deinem-herzen-unioner-li.351339 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/1-fc-union-berlin/1-fc-union-berlin-lieber-fussballgott-sei-noch-einmal-mit-haut-haar-und-deinem-herzen-unioner-li.351339
2023-05-24 16:59:04,068 - root - WARNING - Skipped https://www.berliner-zeitung.de/gesundheit-oekologie/welt-schizophrenie-tag-schizophrenie-wenn-vorurteile-die-erkrankten-zusaetzlich-belasten-li.351401 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/gesundheit-oekologie/welt-schizophrenie-tag-schizophrenie-wenn-vorurteile-die-erkrankten-zusaetzlich-belasten-li.351401
2023-05-24 16:59:04,072 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/waehlen-mit-16-mehrheit-62-prozent-gegen-senkung-des-wahlalters-li.351623 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/waehlen-mit-16-mehrheit-62-prozent-gegen-senkung-des-wahlalters-li.351623
2023-05-24 16:59:04,073 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/trauzeugenaffaere-in-robert-habecks-ministerium-das-ist-das-eigentliche-problem-li.351507 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/trauzeugenaffaere-in-robert-habecks-ministerium-das-ist-das-eigentliche-problem-li.351507
2023-05-24 16:59:04,074 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/zahl-der-opfer-von-moderner-sklaverei-steigt-wegen-globalen-krisen-klimawandel-militaerischen-konflikten-50-millionen-menschen-betroffen-li.351616 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/zahl-der-opfer-von-moderner-sklaverei-steigt-wegen-globalen-krisen-klimawandel-militaerischen-konflikten-50-millionen-menschen-betroffen-li.351616
2023-05-24 16:59:04,074 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/waehrend-schiff-hertha-bald-fahrtuechtig-ist-muss-verein-hertha-entkernt-werden-li.351320 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/waehrend-schiff-hertha-bald-fahrtuechtig-ist-muss-verein-hertha-entkernt-werden-li.351320
2023-05-24 16:59:04,080 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/ukraine-krieg-update-explosion-in-belgorod-eu-liefert-munition-und-raketen-an-kiew-ueberblick-li.351600 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/ukraine-krieg-update-explosion-in-belgorod-eu-liefert-munition-und-raketen-an-kiew-ueberblick-li.351600
2023-05-24 16:59:04,080 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/unfall-vor-mercedes-benz-arena-mann-von-bvg-bus-angefahren-und-lebensgefaehrlich-verletzt-nach-scorpions-konzert-tamara-danz-strasse-am-mercedes-benz-platz-li.351601 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/unfall-vor-mercedes-benz-arena-mann-von-bvg-bus-angefahren-und-lebensgefaehrlich-verletzt-nach-scorpions-konzert-tamara-danz-strasse-am-mercedes-benz-platz-li.351601
2023-05-24 16:59:04,084 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/schummelei-mit-netflix-accounts-so-viel-kostet-bald-ein-zusaetzlicher-nutzer-ausserhalb-von-haushalt-li.351588 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/schummelei-mit-netflix-accounts-so-viel-kostet-bald-ein-zusaetzlicher-nutzer-ausserhalb-von-haushalt-li.351588
2023-05-24 16:59:04,092 - root - WARNING - Skipped https://www.berliner-zeitung.de/mensch-metropole/nahverkehr-neue-vbb-chefin-ute-bonde-wir-koennten-in-berlin-eine-magnetschwebebahn-testen-li.349290 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/mensch-metropole/nahverkehr-neue-vbb-chefin-ute-bonde-wir-koennten-in-berlin-eine-magnetschwebebahn-testen-li.349290
2023-05-24 16:59:04,202 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-brueckenfahrt-berlin-jannowitzbruecke-tickets-xqz-li.221288 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-brueckenfahrt-berlin-jannowitzbruecke-tickets-xqz-li.221288
2023-05-24 16:59:04,235 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/neues-talkkonzept-diese-frau-soll-nachfolgerin-von-anne-will-werden-li.351567 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/neues-talkkonzept-diese-frau-soll-nachfolgerin-von-anne-will-werden-li.351567
2023-05-24 16:59:04,242 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/energie-heizung-strom-verbrauch-neuer-gesetzentwurf-wirtschaftsminister-robert-habeck-gruene-will-das-heizverhalten-der-deutschen-durchleuchten-li.351549 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/energie-heizung-strom-verbrauch-neuer-gesetzentwurf-wirtschaftsminister-robert-habeck-gruene-will-das-heizverhalten-der-deutschen-durchleuchten-li.351549
2023-05-24 16:59:04,243 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-spreefahrt-mueggelsee-koepenick-tickets-xqz-li.218719 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-spreefahrt-mueggelsee-koepenick-tickets-xqz-li.218719
2023-05-24 16:59:04,244 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/belgorod-russisches-freiwilligenkorps-und-seine-neonazi-wurzeln-li.351570 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/belgorod-russisches-freiwilligenkorps-und-seine-neonazi-wurzeln-li.351570
2023-05-24 16:59:04,244 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/wie-der-westen-die-tuerkei-in-die-arme-putins-getrieben-hat-li.349937 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/wie-der-westen-die-tuerkei-in-die-arme-putins-getrieben-hat-li.349937
2023-05-24 16:59:04,246 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/russland-us-journalist-evan-gershkovich-muss-mindestens-bis-30-august-in-haft-bleiben-li.351568 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/russland-us-journalist-evan-gershkovich-muss-mindestens-bis-30-august-in-haft-bleiben-li.351568
2023-05-24 16:59:04,247 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/kriminalitaet-schleswig-holstein-afd-politiker-bent-lund-vor-seiner-wohnung-niedergestochen-iraker-festgenommen-li.351554 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/kriminalitaet-schleswig-holstein-afd-politiker-bent-lund-vor-seiner-wohnung-niedergestochen-iraker-festgenommen-li.351554
2023-05-24 16:59:04,248 - root - WARNING - Skipped https://www.berliner-zeitung.de/stil-individualitaet/mode-fashion-76-cannes-filmfestspiele-2023-die-7-besten-looks-und-eine-lobende-erwaehnung-isabell-huppert-balenciaga-emilia-schuele-gucci-chanel-valentino-dior-li.351319 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/stil-individualitaet/mode-fashion-76-cannes-filmfestspiele-2023-die-7-besten-looks-und-eine-lobende-erwaehnung-isabell-huppert-balenciaga-emilia-schuele-gucci-chanel-valentino-dior-li.351319
2023-05-24 16:59:04,248 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/arno-duebel-deutschlands-bekanntester-arbeitsloser-ist-tot-li.351571 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/arno-duebel-deutschlands-bekanntester-arbeitsloser-ist-tot-li.351571
2023-05-24 16:59:04,381 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/faeser-gegen-weitere-stationare-grenzkontrollen-li.351546 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/faeser-gegen-weitere-stationare-grenzkontrollen-li.351546
2023-05-24 16:59:04,392 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schifffahrt-mueggelsee-mueggelberge-koepenick-tickets-xqz-li.221933 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schifffahrt-mueggelsee-mueggelberge-koepenick-tickets-xqz-li.221933
2023-05-24 16:59:04,399 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/berlin-autoverkehr-fussgaenger-raus-autos-rein-reine-symbolpolitik-das-sind-die-reaktionen-zur-oeffnung-der-friedrichstrasse-li.351425 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/berlin-autoverkehr-fussgaenger-raus-autos-rein-reine-symbolpolitik-das-sind-die-reaktionen-zur-oeffnung-der-friedrichstrasse-li.351425
2023-05-24 16:59:04,400 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/abendliche-schiffstour-citytour-berlin-tickets-xqz-li.215318 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/abendliche-schiffstour-citytour-berlin-tickets-xqz-li.215318
2023-05-24 16:59:04,415 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-spree-solarkatamaran-tickets-xqz-li.196907 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-spree-solarkatamaran-tickets-xqz-li.196907
2023-05-24 16:59:04,421 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schifffahrt-berlin-hauptbahnhof-spree-tickets-xqz-li.331219 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schifffahrt-berlin-hauptbahnhof-spree-tickets-xqz-li.331219
2023-05-24 16:59:04,429 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/wissenschaft-experimentelle-psychologie-schwarze-und-weisse-luegen-wie-man-luegnern-auf-die-spur-kommt-li.350605 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/wissenschaft-experimentelle-psychologie-schwarze-und-weisse-luegen-wie-man-luegnern-auf-die-spur-kommt-li.350605
2023-05-24 16:59:04,429 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-berlin-abends-spree-solarkatamaran-tickets-xqz-li.235139 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-berlin-abends-spree-solarkatamaran-tickets-xqz-li.235139
2023-05-24 16:59:04,441 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/erlesene-literatur-im-admiralspalast-berlin-tickets-xqz-li.333859 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/erlesene-literatur-im-admiralspalast-berlin-tickets-xqz-li.333859
2023-05-24 16:59:04,442 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/sucharit-bhakdi-vom-vorwurf-der-volksverhetzung-freigesprochen-li.351543 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/sucharit-bhakdi-vom-vorwurf-der-volksverhetzung-freigesprochen-li.351543
2023-05-24 16:59:04,566 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/ballett-dornroeschen-berlin-2023-tickets-xqz-li.345120 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/ballett-dornroeschen-berlin-2023-tickets-xqz-li.345120
2023-05-24 16:59:04,567 - root - WARNING - Skipped https://www.berliner-zeitung.de/panorama/leute-promis-gntm-star-theresia-fischer-schockt-fans-mit-fotos-nach-beinverlaengerung-li.351462 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/panorama/leute-promis-gntm-star-theresia-fischer-schockt-fans-mit-fotos-nach-beinverlaengerung-li.351462
2023-05-24 16:59:04,572 - root - WARNING - Skipped https://www.berliner-zeitung.de/mensch-metropole/amtsgericht-tiergarten-prozess-gegen-krankenpfleger-jacek-a-beatmungsgeraet-bei-baby-abgestellt-pfleger-in-berlin-zu-geldstrafe-verurteilt-li.351509 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/mensch-metropole/amtsgericht-tiergarten-prozess-gegen-krankenpfleger-jacek-a-beatmungsgeraet-bei-baby-abgestellt-pfleger-in-berlin-zu-geldstrafe-verurteilt-li.351509
2023-05-24 16:59:04,574 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-schulklassen-klassenfahrt-berlin-tickets-xqz-li.214863 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-schulklassen-klassenfahrt-berlin-tickets-xqz-li.214863
2023-05-24 16:59:04,575 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/wohnen-berlin-mieterbund-praesident-lukas-siebenkotten-alles-was-legal-ist-wird-in-den-naechsten-jahren-ausgenutzt-werden-li.351503 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/wohnen-berlin-mieterbund-praesident-lukas-siebenkotten-alles-was-legal-ist-wird-in-den-naechsten-jahren-ausgenutzt-werden-li.351503
2023-05-24 16:59:04,575 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/ukraine-kampfjet-koalition-nimmt-gestalt-an-deutschland-prueft-beteiligung-li.351539 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/ukraine-kampfjet-koalition-nimmt-gestalt-an-deutschland-prueft-beteiligung-li.351539
2023-05-24 16:59:04,576 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-7-seen-rundfahrt-wannsee-tickets-xqz-li.217726 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schiffstour-7-seen-rundfahrt-wannsee-tickets-xqz-li.217726
2023-05-24 16:59:04,576 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/bericht-bund-will-digitales-postfach-fuer-jeden-schaffen-li.351535 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/bericht-bund-will-digitales-postfach-fuer-jeden-schaffen-li.351535
2023-05-24 16:59:04,580 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/die-groessten-klimasuender-in-der-eu-deutschland-und-polen-fuehren-brisante-liste-an-li.351512 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/die-groessten-klimasuender-in-der-eu-deutschland-und-polen-fuehren-brisante-liste-an-li.351512
2023-05-24 16:59:04,583 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/heizen-robert-habeck-buerokratische-huerde-waermepumpe-scheitert-in-berlin-an-zwei-zentimetern-abstand-wars-das-mit-der-heizwende-li.350886 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/heizen-robert-habeck-buerokratische-huerde-waermepumpe-scheitert-in-berlin-an-zwei-zentimetern-abstand-wars-das-mit-der-heizwende-li.350886
2023-05-24 16:59:04,735 - root - WARNING - Warning! Couldn't reach sitemap https://www.berliner-zeitung.de/news-sitemap.xml so skipped it. Exception: 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news-sitemap.xml
2023-05-24 17:00:13,182 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/caren-miosga-anne-will-talkshow-1.5879283 -> https://www.sueddeutsche.de/kultur/caren-miosga-anne-will-talkshow-1.5879283?reduced=true
2023-05-24 17:00:13,203 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/wirtschaft/dsgvo-jahrestag-ueberwachung-datenschutz-behoerden-1.5879012 -> https://www.sueddeutsche.de/wirtschaft/dsgvo-jahrestag-ueberwachung-datenschutz-behoerden-1.5879012?reduced=true
2023-05-24 17:00:13,207 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/justiz-mord-prozesse-kommentar-1.5878835 -> https://www.sueddeutsche.de/meinung/justiz-mord-prozesse-kommentar-1.5878835?reduced=true
2023-05-24 17:00:16,245 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 81, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 17:00:16,475 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/houellebecq-frankreich-1.5879228 -> https://www.sueddeutsche.de/kultur/houellebecq-frankreich-1.5879228?reduced=true
2023-05-24 17:00:16,555 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/bayern/bayern-synagoge-regensburg-schuhplattler-juedische-gemeinde-1.5879327 -> https://www.sueddeutsche.de/bayern/bayern-synagoge-regensburg-schuhplattler-juedische-gemeinde-1.5879327?reduced=true
2023-05-24 17:00:16,561 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/bayern/coburg-polizei-angriff-jugendlicher-obdachloser-1.5879337 -> https://www.sueddeutsche.de/bayern/coburg-polizei-angriff-jugendlicher-obdachloser-1.5879337?reduced=true
2023-05-24 17:01:07,233 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/caren-miosga-anne-will-talkshow-1.5879283 -> https://www.sueddeutsche.de/kultur/caren-miosga-anne-will-talkshow-1.5879283?reduced=true
2023-05-24 17:01:07,234 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/wirtschaft/dsgvo-jahrestag-ueberwachung-datenschutz-behoerden-1.5879012 -> https://www.sueddeutsche.de/wirtschaft/dsgvo-jahrestag-ueberwachung-datenschutz-behoerden-1.5879012?reduced=true
2023-05-24 17:01:07,350 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/justiz-mord-prozesse-kommentar-1.5878835 -> https://www.sueddeutsche.de/meinung/justiz-mord-prozesse-kommentar-1.5878835?reduced=true
2023-05-24 17:01:07,476 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 81, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 17:01:07,700 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/houellebecq-frankreich-1.5879228 -> https://www.sueddeutsche.de/kultur/houellebecq-frankreich-1.5879228?reduced=true
2023-05-24 17:31:53,521 - root - INFO - Got redirected 1 time(s) from https://www.welt.de/regionales/baden-wuerttemberg/article245505412/Tuebinger-Verpackungssteuer-auf-dem-Pruefstand.html -> https://www.welt.de/regionales/baden-wuerttemberg/article245505412/Urteil-Tuebingen-darf-Verpackungssteuer-erheben.html
2023-05-24 17:37:20,834 - root - ERROR - Run into an error processing 'https://www.focus.de/focustv/k1-magazin/k1-magazin-donnerstag-den-25-05-2023-um-22-15-uhr-bei-kabel-eins-mit-diesen-themen_id_194679066.html'
2023-05-24 17:37:20,840 - fundus_crash_focus_2023-05-24 - ERROR - Invalid control character at: line 9 column 115 (char 620)

Run into an error processing 'https://www.focus.de/focustv/k1-magazin/k1-magazin-donnerstag-den-25-05-2023-um-22-15-uhr-bei-kabel-eins-mit-diesen-themen_id_194679066.html'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 52, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/pipeline.py", line 40, in run
    yield from robin
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/more_itertools/more.py", line 1016, in <genexpr>
    return (x for x in i if x is not _marker)
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 63, in scrape
    raise err
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 54, in scrape
    extraction = self.parser(article_source.crawl_date).parse(article_source.html, error_handling)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 192, in parse
    self._base_setup(html)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 186, in _base_setup
    lds = [json.loads(node.text_content()) for node in ld_nodes]
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 186, in <listcomp>
    lds = [json.loads(node.text_content()) for node in ld_nodes]
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 9 column 115 (char 620)

Run into an error processing 'https://www.focus.de/focustv/k1-magazin/k1-magazin-donnerstag-den-25-05-2023-um-22-15-uhr-bei-kabel-eins-mit-diesen-themen_id_194679066.html'
2023-05-24 17:37:21,286 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/prozess-sexuelle-noetigung-polizei-metoo-stuttgart-1.5879117 -> https://www.sueddeutsche.de/politik/prozess-sexuelle-noetigung-polizei-metoo-stuttgart-1.5879117?reduced=true
2023-05-24 17:37:21,457 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 17:37:22,515 - root - ERROR - Run into an error processing 'https://www.sueddeutsche.de/projekte/artikel/wirtschaft/argentinien-inflation-peso-schein-e789374/'
2023-05-24 17:37:22,520 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - Found no type for LD

Run into an error processing 'https://www.sueddeutsche.de/projekte/artikel/wirtschaft/argentinien-inflation-peso-schein-e789374/'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 52, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/pipeline.py", line 40, in run
    yield from robin
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/more_itertools/more.py", line 1016, in <genexpr>
    return (x for x in i if x is not _marker)
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 63, in scrape
    raise err
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 54, in scrape
    extraction = self.parser(article_source.crawl_date).parse(article_source.html, error_handling)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 192, in parse
    self._base_setup(html)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 188, in _base_setup
    self.precomputed = Precomputed(html, doc, get_meta_content(doc), LinkedDataMapping(collapsed_lds))
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/data.py", line 47, in __init__
    self.add_ld(ld)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/data.py", line 58, in add_ld
    raise ValueError(f"Found no type for LD")
ValueError: Found no type for LD

Run into an error processing 'https://www.sueddeutsche.de/projekte/artikel/wirtschaft/argentinien-inflation-peso-schein-e789374/'
2023-05-24 17:38:55,328 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/brandenburg-270-straftaten-in-zusammenhang-mit-ukrainekrieg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fbrandenburg-270-straftaten-in-zusammenhang-mit-ukrainekrieg
2023-05-24 17:38:55,345 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/razzia-gegen-klimaschuetzer-letzte-generation-macht-weiter -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Frazzia-gegen-klimaschuetzer-letzte-generation-macht-weiter
2023-05-24 17:38:55,364 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/habeck-offen-fuer-strengere-transparenz-regeln -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fhabeck-offen-fuer-strengere-transparenz-regeln
2023-05-24 17:38:55,365 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/23/scholz-beim-staedtetag-kritikpunkte-waerme-und-gefluechtete -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F23%2Fscholz-beim-staedtetag-kritikpunkte-waerme-und-gefluechtete
2023-05-24 17:38:55,366 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/2023/22/ampel-koalition-streit-heizungsgesetz-geg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2F2023%2F22%2Fampel-koalition-streit-heizungsgesetz-geg
2023-05-24 17:38:55,367 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/gruene-kritisieren-fehlende-transparenz-beim-haushalt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fgruene-kritisieren-fehlende-transparenz-beim-haushalt
2023-05-24 17:38:55,368 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/23/tuebinger-verpackungssteuer-auf-dem-pruefstand -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F23%2Ftuebinger-verpackungssteuer-auf-dem-pruefstand
2023-05-24 17:38:55,369 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/mann-wollte-mehr-bier-heimflucht-endet-im-gleisbett -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fmann-wollte-mehr-bier-heimflucht-endet-im-gleisbett
2023-05-24 17:38:55,371 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/krieg-gegen-die-ukraine-so-ist-die-lage -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fkrieg-gegen-die-ukraine-so-ist-die-lage
2023-05-24 17:38:55,372 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/suedwest-polizei-bekommt-tausende-lampen-fuer-ausweiskontrolle -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fsuedwest-polizei-bekommt-tausende-lampen-fuer-ausweiskontrolle
2023-05-24 17:38:55,477 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/ausland/2023-05/schweiz-leopard-2-panzern-rueckkauf-rheinmetall -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fausland%2F2023-05%2Fschweiz-leopard-2-panzern-rueckkauf-rheinmetall
2023-05-24 17:38:55,479 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/gut-leben-und-arbeiten-debatte-ueber-stadtentwicklung -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fgut-leben-und-arbeiten-debatte-ueber-stadtentwicklung
2023-05-24 17:38:55,481 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/mehrfacher-kindesmissbrauch-haft-fuer-35-jaehrigen-betreuer -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fmehrfacher-kindesmissbrauch-haft-fuer-35-jaehrigen-betreuer
2023-05-24 17:38:55,482 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/einigung-auf-globale-ueberwachung-von-treibhausgasen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Feinigung-auf-globale-ueberwachung-von-treibhausgasen
2023-05-24 17:38:55,505 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/2023-05/letzte-generation-bundesweite-razzia-klimaaktivisten-nachrichtenpodcast -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2F2023-05%2Fletzte-generation-bundesweite-razzia-klimaaktivisten-nachrichtenpodcast
2023-05-24 17:39:44,164 - root - ERROR - Run into an error processing 'https://www.berliner-zeitung.de/ticketshop/erlesene-literatur-im-admiralspalast-berlin-tickets-xqz-li.333859'
2023-05-24 17:39:44,172 - fundus_crash_berliner-zeitung_2023-05-24 - ERROR - Invalid control character at: line 11 column 211 (char 595)

Run into an error processing 'https://www.berliner-zeitung.de/ticketshop/erlesene-literatur-im-admiralspalast-berlin-tickets-xqz-li.333859'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 52, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/pipeline.py", line 40, in run
    yield from robin
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/more_itertools/more.py", line 1016, in <genexpr>
    return (x for x in i if x is not _marker)
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 63, in scrape
    raise err
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 54, in scrape
    extraction = self.parser(article_source.crawl_date).parse(article_source.html, error_handling)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 192, in parse
    self._base_setup(html)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 186, in _base_setup
    lds = [json.loads(node.text_content()) for node in ld_nodes]
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 186, in <listcomp>
    lds = [json.loads(node.text_content()) for node in ld_nodes]
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Invalid control character at: line 11 column 211 (char 595)

Run into an error processing 'https://www.berliner-zeitung.de/ticketshop/erlesene-literatur-im-admiralspalast-berlin-tickets-xqz-li.333859'
2023-05-24 17:39:46,758 - root - INFO - Got redirected 1 time(s) from https://www.tagesschau.de/ausland/amerika/11km-podcast-usa-einwanderungspolitik-100.html -> https://www.ardaudiothek.de/sendung/11km-der-tagesschau-podcast/12200383/
2023-05-24 17:39:47,715 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/verkehr-braucht-klimakurs/a-65722985?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/verkehr-nicht-auf-klimakurs-bericht-internationales-transport-forum-its-pkw-mobilit%C3%A4t/a-65722985?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:39:54,568 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/wettskandal-wirft-dunkle-schatten-über-brasiliens-fußball/a-65706538?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/wettskandal-wirft-dunkle-schatten-ueber-brasiliens-fussball/a-65706538?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:39:54,583 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/investoren-für-die-fußball-bundesliga/a-65708519?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/investoren-fuer-die-fussball-bundesliga/a-65708519?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:39:58,540 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/fc-bayern-münchen-steckt-in-der-krise/a-65696062?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/fc-bayern-muenchen-steckt-in-der-krise/a-65696062?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:39:58,628 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/160-jahre-spd-k-ein-grund-zum-feiern/a-65676944?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/160-jahre-spd-kein-grund-zum-feiern/a-65676944?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:40:02,392 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/cannes-2023-highlights-der-ersten-tage/a-65677019?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/cannes-2023-filme-roter-teppich/a-65677019?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:40:05,606 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/furcht-deutscher-firmen-vor-hackern-groß-wie-nie/a-65637857?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/furcht-deutscher-firmen-vor-hackern-ist-so-gro%C3%9F-wie-nie/a-65637857?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 17:40:28,946 - root - INFO - Got redirected 2 time(s) from https://www.dw.com/de/head-of-corporate-communications/a-65719366 -> https://corporate.dw.com/de/head-of-corporate-communications/a-65719366
2023-05-24 17:40:57,987 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/schleswig-holstein/Warnstreik-im-Einzelhandel-in-SH-Auswirkungen-sind-ueberschaubar,einzelhandel524.html -> https://www.ndr.de/nachrichten/schleswig-holstein/Warnstreik-im-Einzelhandel-in-SH-Auswirkungen-waren-ueberschaubar,einzelhandel524.html
2023-05-24 17:41:03,469 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/niedersachsen/Bad-Harzburg-88-Jaehrige-erfasst-vor-Schule-mehrere-Menschen,unfall17708.html -> https://www.ndr.de/nachrichten/niedersachsen/Bad-Harzburg-88-Jaehrige-faehrt-vor-Schule-mehrere-Menschen-an,unfall17708.html
2023-05-24 17:41:09,856 - fundus_crash_ndr_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 17:41:11,015 - fundus_crash_ndr_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 17:41:14,165 - fundus_crash_ndr_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 17:41:17,958 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/kultur/buch/Neu-Buecher-Romane-Literatur-2023-Buchempfehlungen-Neuerscheinungen,literaturausblick130.html -> https://www.ndr.de/kultur/buch/Neue-Buecher-Romane-Literatur-2023-Buchempfehlungen-Neuerscheinungen,literaturausblick130.html
2023-05-24 17:41:20,354 - root - ERROR - Run into an error processing 'https://www.ndr.de/ratgeber/gesundheit/Krank-auf-Reisen-im-Ausland-Was-tun,krankaufreisen100.html'
2023-05-24 17:41:20,364 - fundus_crash_ndr_2023-05-24 - ERROR - Expecting ',' delimiter: line 86 column 1 (char 5148)

Run into an error processing 'https://www.ndr.de/ratgeber/gesundheit/Krank-auf-Reisen-im-Ausland-Was-tun,krankaufreisen100.html'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 52, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/pipeline.py", line 40, in run
    yield from robin
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/more_itertools/more.py", line 1016, in <genexpr>
    return (x for x in i if x is not _marker)
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 63, in scrape
    raise err
  File "/home/aaron/Code/Python/Fundus/src/fundus/scraping/scraper.py", line 54, in scrape
    extraction = self.parser(article_source.crawl_date).parse(article_source.html, error_handling)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 192, in parse
    self._base_setup(html)
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 186, in _base_setup
    lds = [json.loads(node.text_content()) for node in ld_nodes]
  File "/home/aaron/Code/Python/Fundus/src/fundus/parser/base_parser.py", line 186, in <listcomp>
    lds = [json.loads(node.text_content()) for node in ld_nodes]
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/aaron/.conda/envs/qse/lib/python3.9/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
json.decoder.JSONDecodeError: Expecting ',' delimiter: line 86 column 1 (char 5148)

Run into an error processing 'https://www.ndr.de/ratgeber/gesundheit/Krank-auf-Reisen-im-Ausland-Was-tun,krankaufreisen100.html'
2023-05-24 19:53:52,422 - root - INFO - Got redirected 1 time(s) from https://www.welt.de/wirtschaft/article245520314/Scholz-Wachstumsversprechen-Die-Entzauberung-des-gruenen-Wirtschaftswunders.html -> https://www.welt.de/wirtschaft/plus245520314/Scholz-Wachstumsversprechen-Die-Entzauberung-des-gruenen-Wirtschaftswunders.html
2023-05-24 19:59:18,692 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080 -> https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080?reduced=true
2023-05-24 19:59:18,789 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 19:59:18,877 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:01:30,782 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080 -> https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080?reduced=true
2023-05-24 20:01:30,959 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:01:31,023 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:01:34,874 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/paderborns-kwasniok-auf-mallorca-voruebergehend-festgenommen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fpaderborns-kwasniok-auf-mallorca-voruebergehend-festgenommen
2023-05-24 20:01:34,885 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/medien-goetze-hat-offenbar-ausstiegsklausel-bei-eintracht -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fmedien-goetze-hat-offenbar-ausstiegsklausel-bei-eintracht
2023-05-24 20:01:34,894 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/spd-will-mit-gruenen-und-linken-koalitionsgespraeche-aufnehmen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fspd-will-mit-gruenen-und-linken-koalitionsgespraeche-aufnehmen
2023-05-24 20:01:34,899 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/koalitionsgespraeche-bremer-spd-setzt-auf-rot-gruen-rot -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fkoalitionsgespraeche-bremer-spd-setzt-auf-rot-gruen-rot
2023-05-24 20:01:34,901 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/2023-05/bundeswehr-leopard-panzer-bundestag -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2F2023-05%2Fbundeswehr-leopard-panzer-bundestag
2023-05-24 20:01:34,922 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/zu-viele-offene-fragen-schalke-bezieht-position -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fzu-viele-offene-fragen-schalke-bezieht-position
2023-05-24 20:01:34,923 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/75-jaehriger-kentert-mit-kanu-auf-dem-rhein -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2F75-jaehriger-kentert-mit-kanu-auf-dem-rhein
2023-05-24 20:01:34,924 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/deutschland/2023-05/bremen-koalition-wahl-spd-gruene-linke -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fdeutschland%2F2023-05%2Fbremen-koalition-wahl-spd-gruene-linke
2023-05-24 20:01:34,925 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/zugstrecke-leipzig-dresden-nach-sperrung-wieder-frei -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fzugstrecke-leipzig-dresden-nach-sperrung-wieder-frei
2023-05-24 20:01:34,927 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/gesellschaft/zeitgeschehen/2023-05/cdu-csu-bundesprogramm-patriotismus -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fgesellschaft%2Fzeitgeschehen%2F2023-05%2Fcdu-csu-bundesprogramm-patriotismus
2023-05-24 20:01:58,902 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080 -> https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080?reduced=true
2023-05-24 20:01:58,983 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:01:59,060 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:02:02,617 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/gesellschaft/zeitgeschehen/2023-05/cdu-csu-bundesprogramm-patriotismus -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fgesellschaft%2Fzeitgeschehen%2F2023-05%2Fcdu-csu-bundesprogramm-patriotismus
2023-05-24 20:02:02,629 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/medien-goetze-hat-offenbar-ausstiegsklausel-bei-eintracht -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fmedien-goetze-hat-offenbar-ausstiegsklausel-bei-eintracht
2023-05-24 20:02:02,638 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/deutschland/2023-05/bremen-koalition-wahl-spd-gruene-linke -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fdeutschland%2F2023-05%2Fbremen-koalition-wahl-spd-gruene-linke
2023-05-24 20:02:02,643 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/zu-viele-offene-fragen-schalke-bezieht-position -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fzu-viele-offene-fragen-schalke-bezieht-position
2023-05-24 20:02:02,646 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/spd-will-mit-gruenen-und-linken-koalitionsgespraeche-aufnehmen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fspd-will-mit-gruenen-und-linken-koalitionsgespraeche-aufnehmen
2023-05-24 20:02:02,647 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/75-jaehriger-kentert-mit-kanu-auf-dem-rhein -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2F75-jaehriger-kentert-mit-kanu-auf-dem-rhein
2023-05-24 20:02:02,658 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/2023-05/bundeswehr-leopard-panzer-bundestag -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2F2023-05%2Fbundeswehr-leopard-panzer-bundestag
2023-05-24 20:02:02,659 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/zugstrecke-leipzig-dresden-nach-sperrung-wieder-frei -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fzugstrecke-leipzig-dresden-nach-sperrung-wieder-frei
2023-05-24 20:02:02,661 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/koalitionsgespraeche-bremer-spd-setzt-auf-rot-gruen-rot -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fkoalitionsgespraeche-bremer-spd-setzt-auf-rot-gruen-rot
2023-05-24 20:02:02,664 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/paderborns-kwasniok-auf-mallorca-voruebergehend-festgenommen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fpaderborns-kwasniok-auf-mallorca-voruebergehend-festgenommen
2023-05-24 20:02:07,069 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/verkehr-braucht-klimakurs/a-65722985?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/verkehr-nicht-auf-klimakurs-bericht-internationales-transport-forum-its-pkw-mobilit%C3%A4t/a-65722985?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 20:02:22,021 - fundus_crash_ndr_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:02:59,318 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080 -> https://www.sueddeutsche.de/muenchen/muenchen-fahrrad-adfc-strategie-1.5879080?reduced=true
2023-05-24 20:02:59,406 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:02:59,484 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:02:59,564 - fundus_crash_sueddeutsche_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:03:03,659 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/zugstrecke-leipzig-dresden-nach-sperrung-wieder-frei -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fzugstrecke-leipzig-dresden-nach-sperrung-wieder-frei
2023-05-24 20:03:03,666 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/paderborns-kwasniok-auf-mallorca-voruebergehend-festgenommen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fpaderborns-kwasniok-auf-mallorca-voruebergehend-festgenommen
2023-05-24 20:03:03,699 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/koalitionsgespraeche-bremer-spd-setzt-auf-rot-gruen-rot -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fkoalitionsgespraeche-bremer-spd-setzt-auf-rot-gruen-rot
2023-05-24 20:03:03,700 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/medien-goetze-hat-offenbar-ausstiegsklausel-bei-eintracht -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fmedien-goetze-hat-offenbar-ausstiegsklausel-bei-eintracht
2023-05-24 20:03:03,701 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/gesellschaft/zeitgeschehen/2023-05/cdu-csu-bundesprogramm-patriotismus -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fgesellschaft%2Fzeitgeschehen%2F2023-05%2Fcdu-csu-bundesprogramm-patriotismus
2023-05-24 20:03:03,704 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/zu-viele-offene-fragen-schalke-bezieht-position -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fzu-viele-offene-fragen-schalke-bezieht-position
2023-05-24 20:03:03,705 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/deutschland/2023-05/bremen-koalition-wahl-spd-gruene-linke -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fdeutschland%2F2023-05%2Fbremen-koalition-wahl-spd-gruene-linke
2023-05-24 20:03:03,707 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/2023-05/bundeswehr-leopard-panzer-bundestag -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2F2023-05%2Fbundeswehr-leopard-panzer-bundestag
2023-05-24 20:03:03,707 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/spd-will-mit-gruenen-und-linken-koalitionsgespraeche-aufnehmen -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2Fspd-will-mit-gruenen-und-linken-koalitionsgespraeche-aufnehmen
2023-05-24 20:03:03,712 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/24/75-jaehriger-kentert-mit-kanu-auf-dem-rhein -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F24%2F75-jaehriger-kentert-mit-kanu-auf-dem-rhein
2023-05-24 20:03:07,273 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/verkehr-braucht-klimakurs/a-65722985?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/verkehr-nicht-auf-klimakurs-bericht-internationales-transport-forum-its-pkw-mobilit%C3%A4t/a-65722985?maca=de-rss-de-all-1119-xml-mrss
2023-05-24 20:03:13,927 - fundus_crash_ndr_2023-05-24 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-24 20:08:18,633 - fundus_crash_2023-05-24 20:08:18.631307 - ERROR - domain
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database(backend_session, backup_session)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 41, in crawl_to_database
    de_de = [el for el in de_de if el.domain.split(".")[1] in original_crawler_mapping.keys()]
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 41, in <listcomp>
    de_de = [el for el in de_de if el.domain.split(".")[1] in original_crawler_mapping.keys()]
  File "/home/aaron/.conda/envs/qse/lib/python3.9/enum.py", line 429, in __getattr__
    raise AttributeError(name) from None
AttributeError: domain
2023-05-25 07:49:01,020 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:49:01,038 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/medien/lars-klingbeil-lanz-tv-kritik-1.5880162 -> https://www.sueddeutsche.de/medien/lars-klingbeil-lanz-tv-kritik-1.5880162?reduced=true
2023-05-25 07:49:01,055 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:49:01,073 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:49:02,557 - fundus_crash_sueddeutsche_2023-05-25 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 80, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-25 07:50:26,739 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:50:26,761 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/medien/lars-klingbeil-lanz-tv-kritik-1.5880162 -> https://www.sueddeutsche.de/medien/lars-klingbeil-lanz-tv-kritik-1.5880162?reduced=true
2023-05-25 07:50:26,764 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:50:26,832 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:50:27,821 - fundus_crash_sueddeutsche_2023-05-25 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 80, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-25 07:51:27,960 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:51:27,966 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:51:27,975 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:51:31,078 - fundus_crash_sueddeutsche_2023-05-25 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 80, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-25 07:51:32,583 - fundus_crash_sueddeutsche_2023-05-25 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 80, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-25 07:53:17,644 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:53:17,645 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:53:17,778 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:53:17,871 - fundus_crash_sueddeutsche_2023-05-25 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-25 07:53:18,480 - fundus_crash_sueddeutsche_2023-05-25 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 79, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-25 07:54:07,228 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:54:07,229 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:54:07,232 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:54:59,174 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:54:59,176 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:54:59,177 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:55:30,365 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:55:30,372 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:55:30,498 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:55:42,638 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:55:42,658 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:55:42,664 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:56:08,167 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:56:08,168 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:56:08,178 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:58:07,478 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:58:07,547 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:58:07,561 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:59:34,072 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366 -> https://www.sueddeutsche.de/politik/desantis-twitter-musk-trump-usa-kandidatur-1.5880366?reduced=true
2023-05-25 07:59:34,088 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432 -> https://www.sueddeutsche.de/meinung/desantis-biden-trump-florida-kommentar-1.5880432?reduced=true
2023-05-25 07:59:34,119 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379 -> https://www.sueddeutsche.de/politik/republikaner-kandidaten-us-praesident-1.5880379?reduced=true
2023-05-25 07:59:35,685 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/medien/lars-klingbeil-lanz-tv-kritik-1.5880162 -> https://www.sueddeutsche.de/medien/lars-klingbeil-lanz-tv-kritik-1.5880162?reduced=true
2023-05-25 07:59:35,690 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/tina-turner-tot-nachruf-1.5879802 -> https://www.sueddeutsche.de/kultur/tina-turner-tot-nachruf-1.5879802?reduced=true
2023-05-31 06:42:57,996 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/medien/manfred-weber-lanz-tv-kritik-1.5890722 -> https://www.sueddeutsche.de/medien/manfred-weber-lanz-tv-kritik-1.5890722?reduced=true
2023-05-31 06:42:58,939 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/krieg-moskau-ukraine-drohnen-1.5890559 -> https://www.sueddeutsche.de/politik/krieg-moskau-ukraine-drohnen-1.5890559?reduced=true
2023-05-31 06:42:59,412 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/freising/freising-unser-auto-ist-eine-uralte-schrott-kiste-1.5890919 -> https://www.sueddeutsche.de/muenchen/freising/freising-unser-auto-ist-eine-uralte-schrott-kiste-1.5890919?reduced=true
2023-05-31 06:42:59,448 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/dachau/karlsfeld-windrad-windkraft-landkreis-dachau-1.5890345 -> https://www.sueddeutsche.de/muenchen/dachau/karlsfeld-windrad-windkraft-landkreis-dachau-1.5890345?reduced=true
2023-05-31 06:43:00,583 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/erding/hunderennen-grosskoechlham-1.5890758 -> https://www.sueddeutsche.de/muenchen/erding/hunderennen-grosskoechlham-1.5890758?reduced=true
2023-05-31 06:43:00,587 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/freising/mitten-in-der-region-zwei-doofe-ein-gedanke-1.5890913 -> https://www.sueddeutsche.de/muenchen/freising/mitten-in-der-region-zwei-doofe-ein-gedanke-1.5890913?reduced=true
2023-05-31 06:43:01,561 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/landkreismuenchen/graefelfing-laermschutz-a96-1.5890672 -> https://www.sueddeutsche.de/muenchen/landkreismuenchen/graefelfing-laermschutz-a96-1.5890672?reduced=true
2023-05-31 06:43:01,562 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/landkreismuenchen/unterhaching-gemeinderat-wolfgang-panzer-johanna-zapf-streit-1.5890629 -> https://www.sueddeutsche.de/muenchen/landkreismuenchen/unterhaching-gemeinderat-wolfgang-panzer-johanna-zapf-streit-1.5890629?reduced=true
2023-05-31 06:43:02,070 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/wirtschaft/jensen-huang-nvidia-chips-billionen-marke-1.5890564 -> https://www.sueddeutsche.de/wirtschaft/jensen-huang-nvidia-chips-billionen-marke-1.5890564?reduced=true
2023-05-31 06:43:02,083 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/panorama/japan-kriminalitaet-aussenseiter-1.5887683 -> https://www.sueddeutsche.de/panorama/japan-kriminalitaet-aussenseiter-1.5887683?reduced=true
2023-05-31 06:43:02,891 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/selbstbestimmungsgesetz-einwaende-nachbesserungen-1.5890736 -> https://www.sueddeutsche.de/politik/selbstbestimmungsgesetz-einwaende-nachbesserungen-1.5890736?reduced=true
2023-05-31 06:43:45,272 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/61-menschen-gelten-in-mv-als-vermisst -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2F61-menschen-gelten-in-mv-als-vermisst
2023-05-31 06:43:45,282 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/30/grosseinsatz-der-feuerwehr-nach-gasaustritt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F30%2Fgrosseinsatz-der-feuerwehr-nach-gasaustritt
2023-05-31 06:43:45,368 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/329-menschen-gelten-in-schleswig-holstein-als-vermisst -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2F329-menschen-gelten-in-schleswig-holstein-als-vermisst
2023-05-31 06:43:45,371 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/ein-schwerverletzter-nach-unfall-mit-geldtransporter -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Fein-schwerverletzter-nach-unfall-mit-geldtransporter
2023-05-31 06:43:45,457 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/ausland/2023-05/brasilien-landrechte-indigene-gesetz-lula-da-silva-voelkermord -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fausland%2F2023-05%2Fbrasilien-landrechte-indigene-gesetz-lula-da-silva-voelkermord
2023-05-31 06:43:45,458 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/urteil-gegen-mutmassliche-linksextremisten-erwartet -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Furteil-gegen-mutmassliche-linksextremisten-erwartet
2023-05-31 06:43:45,540 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/suedkorea-meldet-start-nordkoreanischer-satellitenrakete -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Fsuedkorea-meldet-start-nordkoreanischer-satellitenrakete
2023-05-31 06:43:45,544 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/ausland/2023-05/ukraine-ueberblick-wolodymyr-selenskyj-bundeskanzler-olaf-scholz-lob-russland-beschuss -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2Fausland%2F2023-05%2Fukraine-ueberblick-wolodymyr-selenskyj-bundeskanzler-olaf-scholz-lob-russland-beschuss
2023-05-31 06:43:45,632 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/30/crew-von-zweiter-privater-mission-wieder-von-iss-abgedockt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F30%2Fcrew-von-zweiter-privater-mission-wieder-von-iss-abgedockt
2023-05-31 06:43:45,636 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/sozialprojekt-musaik-stellt-neue-produktion-vor -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Fsozialprojekt-musaik-stellt-neue-produktion-vor
2023-05-31 06:43:45,732 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/allianz-trend-zur-e-mobilitaet-erhoeht-brandrisiko -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Fallianz-trend-zur-e-mobilitaet-erhoeht-brandrisiko
2023-05-31 06:43:45,733 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/fussgaengerin-nach-autounfall-verletzt-fahrerin-flieht -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Ffussgaengerin-nach-autounfall-verletzt-fahrerin-flieht
2023-05-31 06:43:45,834 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/bis-zu-27-grad-in-berlin-und-brandenburg -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Fbis-zu-27-grad-in-berlin-und-brandenburg
2023-05-31 06:43:45,834 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-05/31/spd-will-weiterbildungsstrategie-fuer-schleswig-holstein -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-05%2F31%2Fspd-will-weiterbildungsstrategie-fuer-schleswig-holstein
2023-05-31 06:43:45,922 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/politik/2023-05/polen-gesetz-russland-donald-tusk-nachrichtenpodcast -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fpolitik%2F2023-05%2Fpolen-gesetz-russland-donald-tusk-nachrichtenpodcast
2023-05-31 06:43:52,563 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/illegal-fussball-spiele-gestreamt-bande-in-england-zu-haft-verurteilt-li.353843 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/illegal-fussball-spiele-gestreamt-bande-in-england-zu-haft-verurteilt-li.353843
2023-05-31 06:43:52,568 - root - WARNING - Skipped https://www.berliner-zeitung.de/stil-individualitaet/neues-video-der-modemarke-omas-in-balenciaga-spring-24-kollektion-li.353818 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/stil-individualitaet/neues-video-der-modemarke-omas-in-balenciaga-spring-24-kollektion-li.353818
2023-05-31 06:43:52,699 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/riesen-glueck-im-unglueck-schulbus-in-italien-stuerzt-100-meter-in-die-tiefe-li.353850 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/riesen-glueck-im-unglueck-schulbus-in-italien-stuerzt-100-meter-in-die-tiefe-li.353850
2023-05-31 06:43:52,701 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/umgangsrecht-wenn-der-hund-zum-scheidungskind-wird-li.353848 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/umgangsrecht-wenn-der-hund-zum-scheidungskind-wird-li.353848
2023-05-31 06:43:52,819 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/hertha-bsc-verpflichtet-daenischen-offensivspieler-gustav-christensen-li.353845 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/hertha-bsc-verpflichtet-daenischen-offensivspieler-gustav-christensen-li.353845
2023-05-31 06:43:52,839 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/haftstrafe-fuer-mr-cum-ex-hanno-berger-aber-wo-ist-die-beute-aus-den-illegalen-steuerdeals-li.353644 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/haftstrafe-fuer-mr-cum-ex-hanno-berger-aber-wo-ist-die-beute-aus-den-illegalen-steuerdeals-li.353644
2023-05-31 06:43:52,958 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/migration-deutschland-und-polen-vereinbaren-mehr-kontrollen-entlang-der-grenze-li.353833 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/migration-deutschland-und-polen-vereinbaren-mehr-kontrollen-entlang-der-grenze-li.353833
2023-05-31 06:43:52,978 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/fc-bayern-rummenigge-in-aufsichtsrat-berufen-li.353839 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/fc-bayern-rummenigge-in-aufsichtsrat-berufen-li.353839
2023-05-31 06:43:53,109 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berliner-senat-plant-bezirke-fuer-die-unterbringung-von-gefluechteten-zu-belohnen-li.353787 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berliner-senat-plant-bezirke-fuer-die-unterbringung-von-gefluechteten-zu-belohnen-li.353787
2023-05-31 06:43:53,110 - root - WARNING - Skipped https://www.berliner-zeitung.de/panorama/das-fischstaebchen-wird-60-was-steckt-im-beliebten-fett-quader-li.352668 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/panorama/das-fischstaebchen-wird-60-was-steckt-im-beliebten-fett-quader-li.352668
2023-05-31 06:43:53,248 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/gaspreishilfen-finanzminister-lindner-verzichtet-auf-besteuerung-li.353806 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/gaspreishilfen-finanzminister-lindner-verzichtet-auf-besteuerung-li.353806
2023-05-31 06:43:53,290 - root - WARNING - Skipped https://www.berliner-zeitung.de/open-source/xi-jinping-sonderbeauftragter-fuer-die-ukraine-li-hui-beendet-reise-kommt-jetzt-endlich-der-frieden-li.353614 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/open-source/xi-jinping-sonderbeauftragter-fuer-die-ukraine-li-hui-beendet-reise-kommt-jetzt-endlich-der-frieden-li.353614
2023-05-31 06:43:53,414 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/mann-vor-bar-in-berlin-hellersdorf-erstochen-polizei-nimmt-drei-maenner-wegen-verdachts-auf-totschlag-fest-li.347579 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/mann-vor-bar-in-berlin-hellersdorf-erstochen-polizei-nimmt-drei-maenner-wegen-verdachts-auf-totschlag-fest-li.347579
2023-05-31 06:43:53,416 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/1-fc-union-berlin/sommerfahrplan-steht-fest-1-fc-union-berlin-verkuendet-vorbereitungsstart-li.353769 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/1-fc-union-berlin/sommerfahrplan-steht-fest-1-fc-union-berlin-verkuendet-vorbereitungsstart-li.353769
2023-05-31 06:43:53,532 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/vom-qualifikanten-zum-finalisten-miami-heat-schreiben-besondere-geschichte-li.353808 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/vom-qualifikanten-zum-finalisten-miami-heat-schreiben-besondere-geschichte-li.353808
2023-05-31 06:43:53,534 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/starker-abwaertssog-deutsche-bank-warnt-vor-umfassender-rezession-in-deutschland-li.353611 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/starker-abwaertssog-deutsche-bank-warnt-vor-umfassender-rezession-in-deutschland-li.353611
2023-05-31 06:43:53,662 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/neues-verpackungsgesetz-koennte-aus-fuer-milliarden-mehrweg-flaschen-bedeuten-li.353740 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/neues-verpackungsgesetz-koennte-aus-fuer-milliarden-mehrweg-flaschen-bedeuten-li.353740
2023-05-31 06:43:53,663 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/nicht-mehr-als-ein-pflichtsieg-alexander-zverev-in-runde-zwei-der-french-open-li.353794 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/nicht-mehr-als-ein-pflichtsieg-alexander-zverev-in-runde-zwei-der-french-open-li.353794
2023-05-31 06:43:53,784 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/gewalt-im-kosovo-nato-verstaerkt-kfor-schutztruppe-li.353778 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/gewalt-im-kosovo-nato-verstaerkt-kfor-schutztruppe-li.353778
2023-05-31 06:43:53,792 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/besetzte-ukrainische-gebiete-russland-gibt-15-millionen-buergern-russische-paesse-li.353784 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/besetzte-ukrainische-gebiete-russland-gibt-15-millionen-buergern-russische-paesse-li.353784
2023-05-31 06:43:53,926 - root - WARNING - Skipped https://www.berliner-zeitung.de/ratgeber/bingoarme-winkearme-woher-kommt-die-schlaffe-haut-am-oberarm-wie-kriegt-man-sie-weg-li.231799 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ratgeber/bingoarme-winkearme-woher-kommt-die-schlaffe-haut-am-oberarm-wie-kriegt-man-sie-weg-li.231799
2023-05-31 06:43:53,953 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/totalschaden-in-berlin-schoeneberg-auto-kracht-gegen-mehrere-wagen-und-baeume-li.353720 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/totalschaden-in-berlin-schoeneberg-auto-kracht-gegen-mehrere-wagen-und-baeume-li.353720
2023-05-31 06:43:54,115 - root - WARNING - Skipped https://www.berliner-zeitung.de/sponsored/open-airs-auf-schloss-neuhardenberg-ins-freie-li.353741 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sponsored/open-airs-auf-schloss-neuhardenberg-ins-freie-li.353741
2023-05-31 06:43:54,116 - root - WARNING - Skipped https://www.berliner-zeitung.de/mensch-metropole/letzte-generation-robin-hood-war-auch-ein-krimineller-li.353630 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/mensch-metropole/letzte-generation-robin-hood-war-auch-ein-krimineller-li.353630
2023-05-31 06:43:54,275 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/kartellamt-leitet-weitere-missbrauchsverfahren-wegen-energiepreisbremsen-ein-li.353684 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/kartellamt-leitet-weitere-missbrauchsverfahren-wegen-energiepreisbremsen-ein-li.353684
2023-05-31 06:43:54,276 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/abgeordnetenhauswahl-berlin/berlin-will-frueheren-flughafen-tegel-laenger-fuer-fluechtlinge-nutzen-li.353715 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/abgeordnetenhauswahl-berlin/berlin-will-frueheren-flughafen-tegel-laenger-fuer-fluechtlinge-nutzen-li.353715
2023-05-31 06:43:54,385 - root - WARNING - Skipped https://www.berliner-zeitung.de/open-mind/feingefuehl-und-uebertreibung-zum-tod-von-peter-simonischek-li.353700 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/open-mind/feingefuehl-und-uebertreibung-zum-tod-von-peter-simonischek-li.353700
2023-05-31 06:43:54,420 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/vogue-germany-portraetiert-special-olympics-athletinnen-li.353738 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/vogue-germany-portraetiert-special-olympics-athletinnen-li.353738
2023-05-31 06:43:54,537 - root - WARNING - Skipped https://www.berliner-zeitung.de/panorama/die-causa-rammstein-sind-missbrauchsvorwuerfe-wirklich-ein-karrierekiller-li.353588 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/panorama/die-causa-rammstein-sind-missbrauchsvorwuerfe-wirklich-ein-karrierekiller-li.353588
2023-05-31 06:43:54,546 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/voellig-inakzeptabel-eu-verurteilt-schockierende-kosovo-gewalt-ruft-zu-ruhe-auf-li.353704 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/voellig-inakzeptabel-eu-verurteilt-schockierende-kosovo-gewalt-ruft-zu-ruhe-auf-li.353704
2023-05-31 06:43:54,654 - root - WARNING - Skipped https://www.berliner-zeitung.de/wirtschaft-verantwortung/lng-terminal-kann-eine-milliarde-euro-den-widerstand-auf-ruegen-besaenftigen-li.353607 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/wirtschaft-verantwortung/lng-terminal-kann-eine-milliarde-euro-den-widerstand-auf-ruegen-besaenftigen-li.353607
2023-05-31 06:43:54,670 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-brandenburg-gericht-erlaubt-protestcamp-gegen-ausreisezentrum-am-flughafen-ber-li.353716 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-brandenburg-gericht-erlaubt-protestcamp-gegen-ausreisezentrum-am-flughafen-ber-li.353716
2023-05-31 06:43:54,787 - root - WARNING - Skipped https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schifffahrt-berlin-hauptbahnhof-spree-tickets-xqz-li.331219 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/ticketshop/schifffahrt-dampferfahrt-in-berlin/schifffahrt-berlin-hauptbahnhof-spree-tickets-xqz-li.331219
2023-05-31 06:43:54,789 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/literatur/katja-oskamp-es-ist-ja-immer-noch-mein-kleines-buch-ueber-marzahn-li.353678 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/literatur/katja-oskamp-es-ist-ja-immer-noch-mein-kleines-buch-ueber-marzahn-li.353678
2023-05-31 06:43:54,921 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-war-im-fruehling-das-zweitwaermste-bundesland-li.353685 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-war-im-fruehling-das-zweitwaermste-bundesland-li.353685
2023-05-31 06:43:54,922 - root - WARNING - Skipped https://www.berliner-zeitung.de/panorama/sophia-thomalla-aeussert-sich-zu-vorwuerfen-gegen-ex-till-lindemann-und-rammstein-li.353636 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/panorama/sophia-thomalla-aeussert-sich-zu-vorwuerfen-gegen-ex-till-lindemann-und-rammstein-li.353636
2023-05-31 06:43:55,100 - root - WARNING - Skipped https://www.berliner-zeitung.de/starkes-team-fuer-sport-li.353674 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/starkes-team-fuer-sport-li.353674
2023-05-31 06:43:55,101 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/kriminalitaet-autoeinbruch-in-berlin-reinickendorf-polizei-erwischt-vier-jugendliche-auf-frischer-tat-li.353652 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/kriminalitaet-autoeinbruch-in-berlin-reinickendorf-polizei-erwischt-vier-jugendliche-auf-frischer-tat-li.353652
2023-05-31 06:43:55,235 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/stinkende-drecksaecke-wagner-gruppe-jewgeni-prigoschin-rastet-nach-drohnenangriff-auf-moskau-aus-li.353655 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/stinkende-drecksaecke-wagner-gruppe-jewgeni-prigoschin-rastet-nach-drohnenangriff-auf-moskau-aus-li.353655
2023-05-31 06:43:55,235 - root - WARNING - Skipped https://www.berliner-zeitung.de/gesundheit-oekologie/warum-rauchen-das-risiko-stark-erhoeht-an-leukaemie-zu-erkranken-li.353400 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/gesundheit-oekologie/warum-rauchen-das-risiko-stark-erhoeht-an-leukaemie-zu-erkranken-li.353400
2023-05-31 06:43:55,358 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/es-gibt-mehr-kinder-in-deutschland-aber-es-bleibt-unter-eu-schnitt-li.353651 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/es-gibt-mehr-kinder-in-deutschland-aber-es-bleibt-unter-eu-schnitt-li.353651
2023-05-31 06:43:55,360 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/deutsche-bahn-fuehrt-neues-abo-fuer-faltraeder-von-brompton-ein-klappraeder-fahrrad-mit-in-zug-li.353661 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/deutsche-bahn-fuehrt-neues-abo-fuer-faltraeder-von-brompton-ein-klappraeder-fahrrad-mit-in-zug-li.353661
2023-05-31 06:43:55,482 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berliner-bei-fussballturnier-in-frankfurt-zusammengeschlagen-lebensgefahr-li.353617 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berliner-bei-fussballturnier-in-frankfurt-zusammengeschlagen-lebensgefahr-li.353617
2023-05-31 06:43:55,490 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/berlin-marzahn-haus-nach-todesfall-geraeumt-wegen-moeglichem-gefahrenstoff-li.353632 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/berlin-marzahn-haus-nach-todesfall-geraeumt-wegen-moeglichem-gefahrenstoff-li.353632
2023-05-31 06:43:55,626 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/wetter-feuer-hitze-hohe-waldbrandgefahr-in-brandenburg-li.353604 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/wetter-feuer-hitze-hohe-waldbrandgefahr-in-brandenburg-li.353604
2023-05-31 06:43:55,629 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/lapvona-von-ottessa-moshfegh-liebe-ist-ein-spezifisch-menschlicher-defekt-li.350793 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/lapvona-von-ottessa-moshfegh-liebe-ist-ein-spezifisch-menschlicher-defekt-li.350793
2023-05-31 06:43:55,740 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/uebersterblichkeit-2022-staerker-gestiegen-als-im-vorjahr-hat-jemand-eine-idee-li.353301 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/uebersterblichkeit-2022-staerker-gestiegen-als-im-vorjahr-hat-jemand-eine-idee-li.353301
2023-05-31 06:43:55,749 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/toni-erdmann-schauspieler-peter-simonischek-im-alter-von-76-jahren-gestorben-li.353597 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/toni-erdmann-schauspieler-peter-simonischek-im-alter-von-76-jahren-gestorben-li.353597
2023-05-31 06:43:55,873 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/diese-urlaubsorte-sind-fuer-deutsche-besonders-guenstig-suedeuropa-tuerkei-albanien-billiger-urlaub-li.353593 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/diese-urlaubsorte-sind-fuer-deutsche-besonders-guenstig-suedeuropa-tuerkei-albanien-billiger-urlaub-li.353593
2023-05-31 06:43:55,886 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/unfall-am-alexanderplatz-junge-von-radfahrer-mitgeschleift-und-verletzt-li.353574 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/unfall-am-alexanderplatz-junge-von-radfahrer-mitgeschleift-und-verletzt-li.353574
2023-05-31 06:43:56,002 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/die-stunde-der-aussenseiter-butler-fuehrt-miami-heat-ins-nba-finale-li.353572 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/die-stunde-der-aussenseiter-butler-fuehrt-miami-heat-ins-nba-finale-li.353572
2023-05-31 06:43:56,016 - root - WARNING - Skipped https://www.berliner-zeitung.de/open-source/gewalt-im-kosovo-und-proteste-in-belgrad-serbiens-praesident-vui-weiss-nicht-weiter-li.353548 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/open-source/gewalt-im-kosovo-und-proteste-in-belgrad-serbiens-praesident-vui-weiss-nicht-weiter-li.353548
2023-05-31 06:43:56,144 - root - WARNING - Skipped https://www.berliner-zeitung.de/mensch-metropole/gemeinschaftsgaerten-vom-top-zum-flop-nach-dem-berliner-regierungswechsel-li.350217 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/mensch-metropole/gemeinschaftsgaerten-vom-top-zum-flop-nach-dem-berliner-regierungswechsel-li.350217
2023-05-31 06:43:56,145 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/vier-millionen-heizungen-muessen-2024-theoretisch-ausgetauscht-werden-austauschpflicht-oelheizungen-und-gasheizungen-nach-30-jahren-li.353569 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/vier-millionen-heizungen-muessen-2024-theoretisch-ausgetauscht-werden-austauschpflicht-oelheizungen-und-gasheizungen-nach-30-jahren-li.353569
2023-05-31 06:43:56,260 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/frankreich-erdbeben-erschuettert-osten-des-landes-li.353562 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/frankreich-erdbeben-erschuettert-osten-des-landes-li.353562
2023-05-31 06:43:56,263 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/wolodymyr-selenskyj-zeitplan-fuer-gegenoffensive-der-ukraine-im-krieg-gegen-russland-steht-li.353545 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/wolodymyr-selenskyj-zeitplan-fuer-gegenoffensive-der-ukraine-im-krieg-gegen-russland-steht-li.353545
2023-05-31 06:43:56,382 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/was-die-wahlen-in-der-tuerkei-und-erdogans-wahlsieg-ueber-die-tuerkische-diaspora-aussagen-und-was-nicht-li.353542 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/was-die-wahlen-in-der-tuerkei-und-erdogans-wahlsieg-ueber-die-tuerkische-diaspora-aussagen-und-was-nicht-li.353542
2023-05-31 06:43:56,389 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/musik/d4vd-im-interview-ich-kille-die-person-nicht-wirklich-sondern-nur-die-gedanken-ep-petals-to-thorns-li.352700 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/musik/d4vd-im-interview-ich-kille-die-person-nicht-wirklich-sondern-nur-die-gedanken-ep-petals-to-thorns-li.352700
2023-05-31 06:43:56,497 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/kampfjet-koalition-kiew-hofft-auf-eurofighter-aus-deutschland-li.353535 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/kampfjet-koalition-kiew-hofft-auf-eurofighter-aus-deutschland-li.353535
2023-05-31 06:43:56,515 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/verletzte-bei-ausschreitungen-serbischer-demonstranten-im-kosovo-tennis-star-novak-djokovic-sorgt-mit-botschaft-fuer-wirbel-li.353540 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/verletzte-bei-ausschreitungen-serbischer-demonstranten-im-kosovo-tennis-star-novak-djokovic-sorgt-mit-botschaft-fuer-wirbel-li.353540
2023-05-31 06:43:56,643 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/russland-buergermeister-berichtet-von-drohnenangriff-auf-moskau-li.353537 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/russland-buergermeister-berichtet-von-drohnenangriff-auf-moskau-li.353537
2023-05-31 06:43:56,647 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/brand-in-wilmersdorf-menschen-springen-aus-wohnung-lebensgefaehrlich-verletzt-li.353533 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/brand-in-wilmersdorf-menschen-springen-aus-wohnung-lebensgefaehrlich-verletzt-li.353533
2023-05-31 06:43:56,766 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/kino-streaming/kino-sandra-hueller-superstar-wie-die-ostdeutsche-schauspielerin-in-cannes-triumphierte-li.353404 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/kino-streaming/kino-sandra-hueller-superstar-wie-die-ostdeutsche-schauspielerin-in-cannes-triumphierte-li.353404
2023-05-31 06:43:56,767 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/russland-setzt-massive-angriffswelle-auf-kiew-fort-mindestens-ein-toter-ukraine-krieg-drohnenangriffe-bombenalarm-in-ukraine-li.353532 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/russland-setzt-massive-angriffswelle-auf-kiew-fort-mindestens-ein-toter-ukraine-krieg-drohnenangriffe-bombenalarm-in-ukraine-li.353532
2023-05-31 06:43:56,895 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/1-fc-union-berlin/1-fc-union-berlin-die-chronik-einer-faszinierenden-saison-li.353348 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/1-fc-union-berlin/1-fc-union-berlin-die-chronik-einer-faszinierenden-saison-li.353348
2023-05-31 06:43:56,899 - root - WARNING - Skipped https://www.berliner-zeitung.de/open-source/ukraine-krieg-rechtliche-grauzone-wird-die-nato-durch-kampfjet-lieferungen-zur-kriegspartei-li.352578 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/open-source/ukraine-krieg-rechtliche-grauzone-wird-die-nato-durch-kampfjet-lieferungen-zur-kriegspartei-li.352578
2023-05-31 06:43:57,028 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/angriff-mit-kettensaege-und-machete-in-berlin-lichtenberg-prozess-beginnt-heute-li.353508 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/angriff-mit-kettensaege-und-machete-in-berlin-lichtenberg-prozess-beginnt-heute-li.353508
2023-05-31 06:43:57,029 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/cum-ex-prozess-steueranwalt-hanno-berger-zu-haftstrafe-verurteilt-li.353517 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/cum-ex-prozess-steueranwalt-hanno-berger-zu-haftstrafe-verurteilt-li.353517
2023-05-31 06:43:57,168 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/wegen-party-japanischer-regierungschef-fumio-kishida-feuert-seinen-eigenen-sohn-shotaro-kishida-li.353499 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/wegen-party-japanischer-regierungschef-fumio-kishida-feuert-seinen-eigenen-sohn-shotaro-kishida-li.353499
2023-05-31 06:43:57,263 - root - WARNING - Skipped https://www.berliner-zeitung.de/sport-leidenschaft/raus-in-runde-eins-struff-und-maria-scheitern-bei-den-french-open-li.353500 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/sport-leidenschaft/raus-in-runde-eins-struff-und-maria-scheitern-bei-den-french-open-li.353500
2023-05-31 06:43:57,386 - root - WARNING - Skipped https://www.berliner-zeitung.de/politik-gesellschaft/internationale-politik-usa-besorgt-ueber-neues-anti-russisches-gesetz-in-polen-li.353494 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/politik-gesellschaft/internationale-politik-usa-besorgt-ueber-neues-anti-russisches-gesetz-in-polen-li.353494
2023-05-31 06:43:57,390 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/nach-wahlsieg-tuerkei-diese-vier-aufgaben-muss-recep-tayyip-erdogan-nun-loesen-li.353498 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/nach-wahlsieg-tuerkei-diese-vier-aufgaben-muss-recep-tayyip-erdogan-nun-loesen-li.353498
2023-05-31 06:43:57,526 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/kosovo-serben-versuchen-stadtverwaltung-in-zvecan-zu-stuermen-li.353497 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/kosovo-serben-versuchen-stadtverwaltung-in-zvecan-zu-stuermen-li.353497
2023-05-31 06:43:57,526 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/ukrainerin-sammelt-geld-fuer-russische-besatzer-lange-haftstrafe-li.353490 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/ukrainerin-sammelt-geld-fuer-russische-besatzer-lange-haftstrafe-li.353490
2023-05-31 06:43:57,669 - root - WARNING - Skipped https://www.berliner-zeitung.de/kultur-vergnuegen/komische-oper-berlin-haendels-saul-eine-der-eindrucksvollsten-chorszenen-der-letzten-jahre-li.353115 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/kultur-vergnuegen/komische-oper-berlin-haendels-saul-eine-der-eindrucksvollsten-chorszenen-der-letzten-jahre-li.353115
2023-05-31 06:43:57,671 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/asylrecht-sachsens-ministerpraesident-michael-kretschmer-cdu-will-fuer-mehr-abschiebungen-verfassung-aendern-zu-viele-asylbewerber-li.353480 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/asylrecht-sachsens-ministerpraesident-michael-kretschmer-cdu-will-fuer-mehr-abschiebungen-verfassung-aendern-zu-viele-asylbewerber-li.353480
2023-05-31 06:43:57,797 - root - WARNING - Skipped https://www.berliner-zeitung.de/news/medizin-nobelpreistraeger-harald-zur-hausen-ist-tot-li.353482 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news/medizin-nobelpreistraeger-harald-zur-hausen-ist-tot-li.353482
2023-05-31 06:43:57,798 - root - WARNING - Skipped https://www.berliner-zeitung.de/mensch-metropole/tuerken-in-berlin-erdogan-stichwahl-nach-der-wahl-in-der-tuerkei-ich-konnte-die-spannung-am-kottbusser-tor-spueren-li.353449 because of 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/mensch-metropole/tuerken-in-berlin-erdogan-stichwahl-nach-der-wahl-in-der-tuerkei-ich-konnte-die-spannung-am-kottbusser-tor-spueren-li.353449
2023-05-31 06:43:57,960 - root - WARNING - Warning! Couldn't reach sitemap https://www.berliner-zeitung.de/news-sitemap.xml so skipped it. Exception: 429 Client Error: Too Many Requests for url: https://www.berliner-zeitung.de/news-sitemap.xml
2023-05-31 06:43:58,376 - root - INFO - Got redirected 1 time(s) from https://www.tagesschau.de/wirtschaft/podcast-11km-spotify-geistermusik-100.html -> https://www.tagesschau.de/multimedia/podcast/11km/11km-feed-100.html
2023-05-31 06:44:04,766 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/tennis-und-rassismus-sloane-stephens-bei-den-french-open/a-65763966?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/sloane-stephens-bei-den-french-open-rassismus-ist-schlimmer-geworden/a-65763966?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:07,485 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/1-fc-heidenheim-steigt-in-die-bundesliga-auf/a-65733861?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/bundesliga-aufstieg-heidenheim-vor-hamburger-sv-dramatisches-saisonfinale/a-65733861?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:07,984 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/krieg-in-der-ukraine-sorgt-für-eklat-bei-french-open/a-65758829?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/tennis-french-open-ukraine-krieg-eklat-zwischen-marta-kostyuk-und-aryna-sabalenka/a-65758829?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:08,263 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/nazi-kunst-hitlers-hengste-und-ihre-geschichte/a-64371475?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/nazi-kunst-im-museum/a-64371475?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:09,061 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/marco-reus-bleibt-der-unvollendete/a-65731410?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/bundesliga-marco-reus-verpasst-borussia-dortmund-erneut-die-meisterschaft/a-65731410?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:11,774 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/charles-q-brown-soll-us-militär-anführen/a-65738232?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/charles-brown-cq-generalstabschef-us-milit%C3%A4r/a-65738232?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:14,741 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/verkehr-braucht-klimakurs/a-65722985?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/verkehr-nicht-auf-klimakurs-bericht-internationales-transport-forum-its-pkw-mobilit%C3%A4t/a-65722985?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:15,701 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/investoren-für-die-fußball-bundesliga/a-65708519?maca=de-rss-de-all-1119-xml-mrss -> https://www.dw.com/de/investoren-fuer-die-fussball-bundesliga/a-65708519?maca=de-rss-de-all-1119-xml-mrss
2023-05-31 06:44:25,332 - root - INFO - Got redirected 2 time(s) from https://www.dw.com/de/70-jahre-dw-gro%C3%9Fbotschaft-von-bundeskanzler-scholz/a-65772951 -> https://corporate.dw.com/de/70-jahre-dw-gro%C3%9Fbotschaft-von-bundeskanzler-scholz/a-65772951
2023-05-31 06:44:26,847 - root - INFO - Got redirected 2 time(s) from https://www.dw.com/de/desenredatos-in-ecuador-mehr-transparenz-durch-datenjournalismus/a-65771277 -> https://akademie.dw.com/de/desenredatos-in-ecuador-mehr-transparenz-durch-datenjournalismus/a-65771277
2023-05-31 06:44:27,514 - root - INFO - Got redirected 2 time(s) from https://www.dw.com/de/entr-paneurop%C3%A4isches-medienprojekt-in-zwei-neuen-sprachen-verf%C3%BCgbar/a-65769528 -> https://corporate.dw.com/de/entr-paneurop%C3%A4isches-medienprojekt-in-zwei-neuen-sprachen-verf%C3%BCgbar/a-65769528
2023-05-31 06:44:48,297 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/niedersachsen/Behinderten-Sohn-getoetet-Urteil-gegen-Mutter-erwartet,prozess8186.html -> https://www.ndr.de/nachrichten/niedersachsen/Behinderten-Sohn-getoetet-Urteil-gegen-Mutter-heute-erwartet,prozess8186.html
2023-05-31 06:44:50,335 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/mecklenburg-vorpommern/Vollsperrung-Sanierung-B105-im-Bereich-Bad-Doberan,kurzmeldungmv11012.html -> https://www.ndr.de/nachrichten/mecklenburg-vorpommern/Vollsperrung-B105-Sanierung-im-Bereich-Bad-Doberan,kurzmeldungmv11012.html
2023-05-31 06:44:53,948 - fundus_crash_ndr_2023-05-31 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 78, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-31 06:44:55,953 - fundus_crash_ndr_2023-05-31 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 78, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-31 06:45:08,555 - fundus_crash_ndr_2023-05-31 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 78, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-31 06:45:11,941 - fundus_crash_ndr_2023-05-31 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 78, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-05-31 06:45:41,373 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/nachrichten/niedersachsen/oldenburg_ostfriesland/Zwei-Festnahmen-nach-wilder-Verfolgungsfahrt,aktuelloldenburg12588.html -> https://www.ndr.de/nachrichten/niedersachsen/oldenburg_ostfriesland/Zwei-Festnahmen-nach-wilder-Verfolgungsfahrt,oldenburg2592.html
2023-05-31 06:45:48,719 - root - INFO - Got redirected 1 time(s) from https://www.ndr.de/ratgeber/reise/Muehlentag-2023-Heute-oeffnen-viele-Muehlen-im-Norden,muehlentag198.html -> https://www.ndr.de/ratgeber/reise/Muehlentag-2023-Am-Pfingstmontag-oeffnen-viele-Muehlen-,muehlentag198.html
2023-06-06 14:23:49,793 - fundus_crash_2023-06-06 14:23:49.790137 - ERROR - name 'Publisher' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 16, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 34, in crawl_to_database
    publishers = backend_session.query(Publisher).scalars().all()
NameError: name 'Publisher' is not defined
2023-06-06 14:24:11,088 - fundus_crash_2023-06-06 14:24:11.088147 - ERROR - 'Query' object has no attribute 'scalars'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 17, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 35, in crawl_to_database
    publishers = backend_session.query(Publisher.url).scalars().all()
AttributeError: 'Query' object has no attribute 'scalars'
2023-06-06 14:24:36,329 - fundus_crash_2023-06-06 14:24:36.329161 - ERROR - Multiple rows were found when exactly one was required
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 17, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 35, in crawl_to_database
    publishers = backend_session.query(Publisher.url).scalar().all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 2833, in scalar
    ret = self.one()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/query.py", line 2806, in one
    return self._iter().one()  # type: ignore
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/result.py", line 1505, in one
    return self._only_one_row(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/result.py", line 788, in _only_one_row
    raise exc.MultipleResultsFound(
sqlalchemy.exc.MultipleResultsFound: Multiple rows were found when exactly one was required
2023-06-06 14:25:38,175 - fundus_crash_2023-06-06 14:25:38.174850 - ERROR - 'Select' object has no attribute 'all'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 17, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 35, in crawl_to_database
    publishers = not backend_session.query(Publisher.url).as_scalar().all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/selectable.py", line 6502, in __getattr__
    return getattr(self.element, attr)
AttributeError: 'Select' object has no attribute 'all'
2023-06-06 14:28:54,912 - fundus_crash_2023-06-06 14:28:54.911858 - ERROR - 'str' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 18, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 39, in crawl_to_database
    original_crawler_mapping = {el.url.split(".")[1]: el for el in publishers}
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 39, in <dictcomp>
    original_crawler_mapping = {el.url.split(".")[1]: el for el in publishers}
AttributeError: 'str' object has no attribute 'url'
2023-06-11 10:20:10,659 - fundus_crash_2023-06-11 10:20:10.656408 - ERROR - 'BZCrawler' object has no attribute 'split'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 18, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 35, in crawl_to_database
    original_crawler_mapping = {el.split(".")[1]: el for el in original_crawlers}
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 35, in <dictcomp>
    original_crawler_mapping = {el.split(".")[1]: el for el in original_crawlers}
AttributeError: 'BZCrawler' object has no attribute 'split'
2023-06-11 10:30:05,442 - fundus_crash_2023-06-11 10:30:05.441332 - ERROR - type object 'CrawlerConfig' has no attribute 'items'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 20, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 52, in crawl_to_database
    for key,value in crawler_config.items():
AttributeError: type object 'CrawlerConfig' has no attribute 'items'
2023-06-11 10:30:32,597 - fundus_crash_2023-06-11 10:30:32.596623 - ERROR - 'ABCMeta' object is not iterable
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 20, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 52, in crawl_to_database
    for key,value in dict(crawler_config).items():
TypeError: 'ABCMeta' object is not iterable
2023-06-11 10:32:10,942 - fundus_crash_2023-06-11 10:32:10.941452 - ERROR - 're.Pattern' object is not iterable
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 20, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 43, in crawl_to_database
    original_crawlers = instantiate_all_crawlers()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/__init__.py", line 25, in instantiate_all_crawlers
    BZCrawler(),
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/impl/crawler_bz.py", line 17, in __init__
    super().__init__(**CrawlerConfig.bz)  # THIS IS NOT BZ BERLIN!)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/crawler_base.py", line 65, in __init__
    urls_to_be_blocked.extend(blocked_urls)
TypeError: 're.Pattern' object is not iterable
2023-06-11 10:32:38,940 - fundus_crash_2023-06-11 10:32:38.940347 - ERROR - __init__() got an unexpected keyword argument 'rss_url_regex'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 20, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 43, in crawl_to_database
    original_crawlers = instantiate_all_crawlers()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/__init__.py", line 25, in instantiate_all_crawlers
    BZCrawler(),
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/impl/crawler_bz.py", line 17, in __init__
    super().__init__(**CrawlerConfig.bz)  # THIS IS NOT BZ BERLIN!)
TypeError: __init__() got an unexpected keyword argument 'rss_url_regex'
2023-06-11 10:33:34,989 - fundus_crash_2023-06-11 10:33:34.988594 - ERROR - name 're' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 20, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 53, in crawl_to_database
    crawler_config[key]["blocked_urls"] = re.compile(
NameError: name 're' is not defined
2023-06-11 10:33:54,556 - fundus_crash_2023-06-11 10:33:54.555087 - ERROR - 'ABCMeta' object is not subscriptable
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in crawl_to_database
    "|".join([re.escape(url) for url in crawler_config[key]["blocked_urls"]])
TypeError: 'ABCMeta' object is not subscriptable
2023-06-11 10:36:47,713 - fundus_crash_2023-06-11 10:36:47.712384 - ERROR - 'str' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 53, in crawl_to_database
    url_config_dict ={el.url:el for el in crawler_config.crawler_config_section}
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 53, in <dictcomp>
    url_config_dict ={el.url:el for el in crawler_config.crawler_config_section}
AttributeError: 'str' object has no attribute 'url'
2023-06-11 10:38:34,818 - fundus_crash_2023-06-11 10:38:34.816753 - ERROR - 'www.ntv.de'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in crawl_to_database
    url_config_dict.update({"www.n-tv.de":url_config_dict["www.ntv.de"]})
KeyError: 'www.ntv.de'
2023-06-11 10:42:53,319 - fundus_crash_2023-06-11 10:42:53.319083 - ERROR - 'NoneType' object is not subscriptable
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 62, in crawl_to_database
    "|".join([re.escape(url) for url in current_config["blocked_urls"]])
TypeError: 'NoneType' object is not subscriptable
2023-06-11 10:44:36,802 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:36,919 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:36,929 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:37,018 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:37,030 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:37,487 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:37,498 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:37,757 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:37,774 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,001 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,016 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,113 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,127 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,267 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,280 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,411 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,592 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,604 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,711 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,722 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,826 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:38,838 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:39,125 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:39,138 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:39,232 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:39,241 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:39,360 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:39,372 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,301 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,312 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,458 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,468 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,556 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,600 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,951 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:40,964 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:41,047 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:41,058 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:41,314 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:44:41,326 - fundus_crash_www.welt.de_2023-06-11 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 92, in crawl_to_database
    publisher_id=current_config.publisher_id,
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-06-11 10:46:08,662 - fundus_crash_2023-06-11 10:46:08.660052 - ERROR - 'blocked_urls'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    "|".join([re.escape(url) for url in current_config["blocked_urls"]])
KeyError: 'blocked_urls'
2023-06-11 10:48:14,119 - fundus_crash_2023-06-11 10:48:14.118556 - ERROR - 'blocked_urls'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 61, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 55, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 21, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 69, in crawl_to_database
    if current_config["blocked_urls"]:
KeyError: 'blocked_urls'
2023-06-11 10:49:00,696 - fundus_crash_www.sueddeutsche.de_2023-06-11 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 106, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-11 10:49:00,887 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/politik/entwicklungsministerin-schulze-indien-g-20-gipfel-1.5920026 -> https://www.sueddeutsche.de/politik/entwicklungsministerin-schulze-indien-g-20-gipfel-1.5920026?reduced=true
2023-06-11 10:49:05,581 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-06/11/fuenf-verletzte-nach-unfall-zwei-menschen-in-lebensgefahr -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-06%2F11%2Ffuenf-verletzte-nach-unfall-zwei-menschen-in-lebensgefahr
2023-06-11 10:49:05,582 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-06/11/kleine-braende-wegen-trockenheit-warnung-vor-brandgefahr -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-06%2F11%2Fkleine-braende-wegen-trockenheit-warnung-vor-brandgefahr
2023-06-11 10:49:05,698 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-06/11/streit-18-jaehriger-lebensgefaehrlich-verletzt -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-06%2F11%2Fstreit-18-jaehriger-lebensgefaehrlich-verletzt
2023-06-11 10:49:05,699 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-06/11/hainer-ueber-aus-fuer-dfl-investor-enttaeuscht -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-06%2F11%2Fhainer-ueber-aus-fuer-dfl-investor-enttaeuscht
2023-06-11 10:49:05,800 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-06/11/1-6-milliarden-jahre-alt-spuren-fruehen-lebens-gefunden -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-06%2F11%2F1-6-milliarden-jahre-alt-spuren-fruehen-lebens-gefunden
2023-06-11 10:49:05,801 - root - INFO - Got redirected 1 time(s) from https://www.zeit.de/news/2023-06/10/soeder-und-aiwanger-attackieren-bundesregierung -> https://www.zeit.de/zustimmung?url=https%3A%2F%2Fwww.zeit.de%2Fnews%2F2023-06%2F10%2Fsoeder-und-aiwanger-attackieren-bundesregierung
2023-06-11 10:49:13,913 - fundus_crash_www.dw.com_2023-06-11 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 106, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-11 10:49:14,001 - fundus_crash_www.dw.com_2023-06-11 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 106, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-11 10:49:14,513 - fundus_crash_www.dw.com_2023-06-11 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 106, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-11 10:49:14,599 - fundus_crash_www.dw.com_2023-06-11 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 106, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-11 10:49:15,189 - fundus_crash_www.dw.com_2023-06-11 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 106, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-13 16:05:02,246 - fundus_crash_www.welt.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,249 - fundus_crash_www.faz.net_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,249 - fundus_crash_www.focus.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,249 - fundus_crash_www.sueddeutsche.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,249 - fundus_crash_www.spiegel.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,249 - fundus_crash_www.sueddeutsche.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,250 - fundus_crash_www.berliner-zeitung.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,250 - fundus_crash_www.tagesschau.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,250 - fundus_crash_www.dw.com_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,250 - fundus_crash_www.stern.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,251 - fundus_crash_www.ntv.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,251 - fundus_crash_www.ndr.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:02,251 - fundus_crash_www.taz.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:46,740 - fundus_crash_www.welt.de_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:05:48,351 - fundus_crash_www.faz.net_2023-06-13 - ERROR - 'news'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 83, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 81, in crawl
    Scraper(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 74, in <genexpr>
    spec.source_mapping[source_type] for source_type in restrict_sources_to
KeyError: 'news'
2023-06-13 16:07:29,970 - fundus_crash_www.welt.de_2023-06-13 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 94, in crawl_to_database
    if not article.id:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-13 16:07:30,776 - fundus_crash_www.faz.net_2023-06-13 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 94, in crawl_to_database
    if not article.id:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-13 16:07:31,059 - fundus_crash_www.focus.de_2023-06-13 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 94, in crawl_to_database
    if not article.id:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-13 16:07:31,347 - fundus_crash_www.sueddeutsche.de_2023-06-13 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 94, in crawl_to_database
    if not article.id:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-13 16:07:31,679 - fundus_crash_www.spiegel.de_2023-06-13 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 94, in crawl_to_database
    if not article.id:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-13 16:09:14,818 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:15,217 - fundus_crash_faz_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:15,521 - fundus_crash_focus_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:15,772 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/muenchen/fuerstenfeldbruck/grafrath-munitionslager-gruener-wasserstoff-energiewende-1.5927967 -> https://www.sueddeutsche.de/muenchen/fuerstenfeldbruck/grafrath-munitionslager-gruener-wasserstoff-energiewende-1.5927967?reduced=true
2023-06-13 16:09:15,780 - fundus_crash_sueddeutsche_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:16,067 - fundus_crash_spiegel_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:19,557 - fundus_crash_sueddeutsche_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:21,410 - fundus_crash_berliner-zeitung_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:21,598 - fundus_crash_tagesschau_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:21,979 - fundus_crash_dw_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:23,417 - fundus_crash_stern_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:23,593 - fundus_crash_ntv_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:23,979 - fundus_crash_ndr_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:09:24,076 - fundus_crash_taz_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.source.url, article.source.html
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:42,268 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:42,277 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:42,757 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:42,768 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:43,216 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:43,232 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:44,107 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:44,120 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:44,413 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-13 16:10:44,424 - fundus_crash_welt_2023-06-13 - ERROR - 'Article' object has no attribute 'source'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.source.url,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'source'
2023-06-21 13:02:54,823 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:54,837 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:54,926 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:54,937 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:55,275 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:55,800 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:55,814 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:55,951 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:55,962 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:56,160 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:56,565 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:56,579 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:56,641 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:56,648 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:56,719 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,108 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764 -> https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764?reduced=true
2023-06-21 13:02:57,114 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,118 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,258 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,265 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,421 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,938 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:57,951 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:58,099 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:58,114 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:02:58,300 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:00,855 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:00,860 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:01,014 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:01,018 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:01,158 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:03,057 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:03,060 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:04,291 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:04,295 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:04,466 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,005 - root - INFO - Got redirected 1 time(s) from https://www.tagesschau.de/inland/gesellschaft/bundesverwaltungsgericht-versammlungsverbot-sachsen-100.html -> https://www.mdr.de/nachrichten/sachsen/urteil-corona-verordnung-versammlungsverbot-bundesverwaltungsgericht-100.html
2023-06-21 13:03:05,012 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,023 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,123 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,135 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,253 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,635 - fundus_crash_www.dw.com_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:05,640 - fundus_crash_www.dw.com_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:06,025 - root - INFO - Got redirected 1 time(s) from https://www.dw.com/de/21062023-langsam-gesprochene-nachrichten/a-65986446 -> https://learngerman.dw.com/de/21062023-langsam-gesprochene-nachrichten/a-65986446
2023-06-21 13:03:06,058 - fundus_crash_www.dw.com_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:06,060 - fundus_crash_www.dw.com_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:03:06,458 - fundus_crash_www.dw.com_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 101, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:13,313 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:13,326 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:13,539 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:13,554 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:13,813 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:14,273 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:14,284 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:14,473 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:14,488 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:14,614 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,005 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,015 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,085 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,093 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,162 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,620 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764 -> https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764?reduced=true
2023-06-21 13:05:15,634 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:05:15,637 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:34,968 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:34,980 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:35,094 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:35,104 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:35,203 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:35,759 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:35,771 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,234 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,247 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,392 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,804 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,814 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,889 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,900 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:36,980 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:37,365 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764 -> https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764?reduced=true
2023-06-21 13:08:37,372 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:37,376 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:37,511 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:08:37,518 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:51,879 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:51,917 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:52,336 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:52,387 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:52,627 - fundus_crash_www.welt.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:53,082 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:53,140 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:53,319 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:53,405 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:53,533 - fundus_crash_www.faz.net_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:53,978 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:54,024 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:54,131 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:54,177 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:12:54,298 - fundus_crash_www.focus.de_2023-06-21 - ERROR - 'Article' object has no attribute 'id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 98, in crawl_to_database
    publisher_article_id=article.id,
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/article.py", line 47, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{item}'")
AttributeError: 'Article' object has no attribute 'id'
2023-06-21 13:14:04,790 - fundus_crash_www.welt.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,791 - fundus_crash_www.faz.net_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,791 - fundus_crash_www.focus.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,792 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,792 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,792 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,793 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,793 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,793 - fundus_crash_www.dw.com_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,794 - fundus_crash_www.stern.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,794 - fundus_crash_www.ntv.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,794 - fundus_crash_www.ndr.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:04,794 - fundus_crash_www.taz.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,079 - fundus_crash_www.welt.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,080 - fundus_crash_www.faz.net_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,080 - fundus_crash_www.focus.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,080 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,080 - fundus_crash_www.spiegel.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,081 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,081 - fundus_crash_www.berliner-zeitung.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,081 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,082 - fundus_crash_www.dw.com_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,082 - fundus_crash_www.stern.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,082 - fundus_crash_www.ntv.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,082 - fundus_crash_www.ndr.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:14:16,083 - fundus_crash_www.taz.de_2023-06-21 - ERROR - name 'NewsMap' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 82, in crawl_to_database
    error_handling="catch", restrict_sources_to=[NewsMap, RSSFeed], only_complete=False, batch_size=2,
NameError: name 'NewsMap' is not defined
2023-06-21 13:17:43,105 - root - INFO - Got redirected 1 time(s) from https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764 -> https://www.sueddeutsche.de/kultur/raubkunst-restitution-privatbesitz-1.5949764?reduced=true
2023-06-21 13:17:43,319 - fundus_crash_www.sueddeutsche.de_2023-06-21 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 103, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-06-21 13:17:51,833 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (62812, 13, null, https://www.tagesschau.de/wissen/klima/luftturbulenzen-flugverke..., null, Studie: Mehr Turbulenzen beim Fliegen durch Klimawandel, Luftturbulenzen im Flugverkehr haben in den vergangenen 40 Jahre..., 2023-06-21 13:11:37.894+02, 2023-06-21 13:17:51.67734+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 13, 'category_id': None, 'url': 'https://www.tagesschau.de/wissen/klima/luftturbulenzen-flugverkehr-100.html', 'publisher_article_id': None, 'title': 'Studie: Mehr Turbulenzen beim Fliegen durch Klimawandel', 'plaintext': 'Luftturbulenzen im Flugverkehr haben in den vergangenen 40 Jahren zugenommen. Laut einer Studie ist der Anstieg über dem Nordatlantik und den USA bes ... (2475 characters truncated) ... ng der Flugzeugkabine, durch Wartungsarbeiten, gelegentliche Schäden am Flugzeug oder durch die Behandlung von Verletzungen bei Crew und Passagieren.', 'publishing_time': datetime.datetime(2023, 6, 21, 13, 11, 37, 894000, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 6, 21, 13, 17, 51, 677340), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (62812, 13, null, https://www.tagesschau.de/wissen/klima/luftturbulenzen-flugverke..., null, Studie: Mehr Turbulenzen beim Fliegen durch Klimawandel, Luftturbulenzen im Flugverkehr haben in den vergangenen 40 Jahre..., 2023-06-21 13:11:37.894+02, 2023-06-21 13:17:51.67734+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 103, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (62812, 13, null, https://www.tagesschau.de/wissen/klima/luftturbulenzen-flugverke..., null, Studie: Mehr Turbulenzen beim Fliegen durch Klimawandel, Luftturbulenzen im Flugverkehr haben in den vergangenen 40 Jahre..., 2023-06-21 13:11:37.894+02, 2023-06-21 13:17:51.67734+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 13, 'category_id': None, 'url': 'https://www.tagesschau.de/wissen/klima/luftturbulenzen-flugverkehr-100.html', 'publisher_article_id': None, 'title': 'Studie: Mehr Turbulenzen beim Fliegen durch Klimawandel', 'plaintext': 'Luftturbulenzen im Flugverkehr haben in den vergangenen 40 Jahren zugenommen. Laut einer Studie ist der Anstieg über dem Nordatlantik und den USA bes ... (2475 characters truncated) ... ng der Flugzeugkabine, durch Wartungsarbeiten, gelegentliche Schäden am Flugzeug oder durch die Behandlung von Verletzungen bei Crew und Passagieren.', 'publishing_time': datetime.datetime(2023, 6, 21, 13, 11, 37, 894000, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 6, 21, 13, 17, 51, 677340), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-06-21 13:17:51,989 - fundus_crash_www.tagesschau.de_2023-06-21 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (62813, 13, null, https://www.tagesschau.de/wirtschaft/verbraucher/fahrrad-eurobik..., null, Bald mehr E-Bikes verkauft als normale Fahrräder, Der Boom der Elektro-Räder ist ungebrochen. Die Branche erwarte..., 2023-06-21 13:08:44.715+02, 2023-06-21 13:17:51.863395+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 13, 'category_id': None, 'url': 'https://www.tagesschau.de/wirtschaft/verbraucher/fahrrad-eurobike-e-bike-trends-100.html', 'publisher_article_id': None, 'title': 'Bald mehr E-Bikes verkauft als normale Fahrräder', 'plaintext': 'Der Boom der Elektro-Räder ist ungebrochen. Die Branche erwartet, dass sie dieses Jahr mehr als die Hälfte des Fahrradmarkts ausmachen werden. E-Bike ... (5006 characters truncated) ... Verletzte und 131 Tote. Dass häufig keine anderen Verkehrsteilnehmer beteiligt sind, deutet darauf hin, dass die E-Bikes oft nicht beherrscht werden.', 'publishing_time': datetime.datetime(2023, 6, 21, 13, 8, 44, 715000, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 6, 21, 13, 17, 51, 863395), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (62813, 13, null, https://www.tagesschau.de/wirtschaft/verbraucher/fahrrad-eurobik..., null, Bald mehr E-Bikes verkauft als normale Fahrräder, Der Boom der Elektro-Räder ist ungebrochen. Die Branche erwarte..., 2023-06-21 13:08:44.715+02, 2023-06-21 13:17:51.863395+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 103, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (62813, 13, null, https://www.tagesschau.de/wirtschaft/verbraucher/fahrrad-eurobik..., null, Bald mehr E-Bikes verkauft als normale Fahrräder, Der Boom der Elektro-Räder ist ungebrochen. Die Branche erwarte..., 2023-06-21 13:08:44.715+02, 2023-06-21 13:17:51.863395+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 13, 'category_id': None, 'url': 'https://www.tagesschau.de/wirtschaft/verbraucher/fahrrad-eurobike-e-bike-trends-100.html', 'publisher_article_id': None, 'title': 'Bald mehr E-Bikes verkauft als normale Fahrräder', 'plaintext': 'Der Boom der Elektro-Räder ist ungebrochen. Die Branche erwartet, dass sie dieses Jahr mehr als die Hälfte des Fahrradmarkts ausmachen werden. E-Bike ... (5006 characters truncated) ... Verletzte und 131 Tote. Dass häufig keine anderen Verkehrsteilnehmer beteiligt sind, deutet darauf hin, dass die E-Bikes oft nicht beherrscht werden.', 'publishing_time': datetime.datetime(2023, 6, 21, 13, 8, 44, 715000, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 6, 21, 13, 17, 51, 863395), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-06-21 13:17:52,147 - root - INFO - Got redirected 1 time(s) from https://www.tagesschau.de/inland/gesellschaft/bundesverwaltungsgericht-versammlungsverbot-sachsen-100.html -> https://www.mdr.de/nachrichten/sachsen/urteil-corona-verordnung-versammlungsverbot-bundesverwaltungsgericht-100.html
2023-06-22 13:53:59,418 - root - INFO - Got redirected 1 time(s) from https://www.faz.net/aktuell/politik/inland/spd-inzwischen-lobt-sogar-die-parlamentarische-linke-den-kanzler-18982399.html -> https://www.faz.net/aktuell/politik/inland/spd-inzwischen-lobt-sogar-die-parlamentarische-linke-olaf-scholz-18982399.html
2023-07-06 15:12:12,076 - fundus_crash_welt_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,079 - fundus_crash_faz_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,080 - fundus_crash_focus_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,080 - fundus_crash_sueddeutsche_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,081 - fundus_crash_spiegel_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,082 - fundus_crash_zeit_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,083 - fundus_crash_berliner-zeitung_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,083 - fundus_crash_tagesschau_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,084 - fundus_crash_dw_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,084 - fundus_crash_stern_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,085 - fundus_crash_ntv_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,085 - fundus_crash_ndr_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,085 - fundus_crash_taz_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:12,086 - fundus_crash_waz_2023-07-06 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-06 15:12:34,443 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.html.url, article.html.content
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:12:34,725 - fundus_crash_faz_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.html.url, article.html.content
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:12:34,967 - fundus_crash_focus_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.html.url, article.html.content
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:12:35,335 - fundus_crash_sueddeutsche_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.html.url, article.html.content
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:12:35,762 - fundus_crash_spiegel_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 59, in crawl_to_database
    article.html.url, article.html.content
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:14:15,602 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:14:15,944 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:14:16,286 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:14:16,569 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:14:17,113 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-06 15:14:17,582 - fundus_crash_welt_2023-07-06 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:11:56,905 - fundus_crash_www.welt.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,906 - fundus_crash_www.faz.net_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,906 - fundus_crash_www.focus.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,906 - fundus_crash_www.merkur.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,906 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,907 - fundus_crash_www.dw.com_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,907 - fundus_crash_www.stern.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,907 - fundus_crash_www.ntv.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,907 - fundus_crash_www.ndr.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,907 - fundus_crash_www.taz.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:11:56,907 - fundus_crash_www.waz.de_2023-07-08 - ERROR - crawl() got an unexpected keyword argument 'batch_size'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 60, in crawl_to_database
    for article in current_fundus_crawler.crawl(
TypeError: crawl() got an unexpected keyword argument 'batch_size'
2023-07-08 10:12:08,052 - fundus_crash_www.welt.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:12:08,369 - fundus_crash_www.faz.net_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:12:08,702 - fundus_crash_www.focus.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:12:09,621 - fundus_crash_www.merkur.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:12:09,927 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:13:04,038 - fundus_crash_www.welt.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:36,278 - fundus_crash_www.welt.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:38,183 - fundus_crash_www.faz.net_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:41,789 - fundus_crash_www.focus.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:42,115 - fundus_crash_www.merkur.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:43,867 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:44,551 - fundus_crash_www.dw.com_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:45,577 - fundus_crash_www.stern.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:18:45,934 - fundus_crash_www.ntv.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:20:20,741 - fundus_crash_www.welt.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:20:21,049 - fundus_crash_www.faz.net_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:20:21,384 - fundus_crash_www.focus.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:20:21,764 - fundus_crash_www.merkur.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in crawl_to_database
    if not filter_url(article.html.url, current_config):
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:21:49,695 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'publisher_article_id_regex_from_url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 75, in crawl_to_database
    article_id = extract_id(article.html.requested_url, str(article.html.content), current_config)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 25, in extract_id
    if config["publisher_article_id_regex_from_url"]:
KeyError: 'publisher_article_id_regex_from_url'
2023-07-08 10:21:49,797 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'publisher_article_id_regex_from_url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 75, in crawl_to_database
    article_id = extract_id(article.html.requested_url, str(article.html.content), current_config)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 25, in extract_id
    if config["publisher_article_id_regex_from_url"]:
KeyError: 'publisher_article_id_regex_from_url'
2023-07-08 10:21:49,885 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'publisher_article_id_regex_from_url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 75, in crawl_to_database
    article_id = extract_id(article.html.requested_url, str(article.html.content), current_config)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 25, in extract_id
    if config["publisher_article_id_regex_from_url"]:
KeyError: 'publisher_article_id_regex_from_url'
2023-07-08 10:21:49,969 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'publisher_article_id_regex_from_url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 75, in crawl_to_database
    article_id = extract_id(article.html.requested_url, str(article.html.content), current_config)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 25, in extract_id
    if config["publisher_article_id_regex_from_url"]:
KeyError: 'publisher_article_id_regex_from_url'
2023-07-08 10:21:50,062 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - 'publisher_article_id_regex_from_url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 75, in crawl_to_database
    article_id = extract_id(article.html.requested_url, str(article.html.content), current_config)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 25, in extract_id
    if config["publisher_article_id_regex_from_url"]:
KeyError: 'publisher_article_id_regex_from_url'
2023-07-08 10:34:48,310 - fundus_crash_www.taz.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:48,341 - fundus_crash_www.taz.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:48,371 - fundus_crash_www.taz.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:48,403 - fundus_crash_www.taz.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:48,427 - fundus_crash_www.taz.de_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:49,524 - fundus_crash_www.orf.at_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:49,681 - fundus_crash_www.orf.at_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:49,902 - fundus_crash_www.orf.at_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:50,154 - fundus_crash_www.orf.at_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:34:50,397 - fundus_crash_www.orf.at_2023-07-08 - ERROR - 'HTML' object has no attribute 'url'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 88, in crawl_to_database
    url=article.html.url,
AttributeError: 'HTML' object has no attribute 'url'
2023-07-08 10:45:16,871 - crash - ERROR - name 'requests' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/__init__.py", line 50, in parse_robots_txt
    robots_str: str = requests.get(f"{base_url}/robots.txt").text
NameError: name 'requests' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 59, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 54, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 27, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 31, in crawl_to_database
    url_config_dict = construct_url_config_dict()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/__init__.py", line 20, in construct_url_config_dict
    urls_from_robots = parse_robots_txt(current_config["url"])
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/__init__.py", line 53, in parse_robots_txt
    except requests.RequestException:
NameError: name 'requests' is not defined
2023-07-08 10:47:54,490 - fundus_crash_www.ndr.de_2023-07-08 - ERROR - 'list' object has no attribute 'search'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 44, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 69, in inner_filter_url
    return filter_url(url, crawler_config)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/crawlers/utility.py", line 60, in filter_url
    url_is_valid = crawler_config["blocked_urls"].search(url) is None
AttributeError: 'list' object has no attribute 'search'
2023-07-08 11:18:39,528 - fundus_crash_www.taz.de_2023-07-08 - ERROR - Server disconnected
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 46, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 139, in run
    for article in gen:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 210, in fetch
    async with session.get(url, headers=self.request_header) as response:
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/aiohttp/client.py", line 1141, in __aenter__
    self._resp = await self._coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/aiohttp/client.py", line 560, in _request
    await resp.start(conn)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/aiohttp/client_reqrep.py", line 899, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/aiohttp/streams.py", line 616, in read
    await self._waiter
aiohttp.client_exceptions.ServerDisconnectedError: Server disconnected
2023-07-08 11:21:11,956 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689912, 5, null, https://www.zeit.de/news/2023-07/08/brand-eines-autohauses-schad..., null, Landau in der Pfalz: Brand eines Autohauses: Schaden in Millione..., Ein Autohaus im pfälzischen Landau ist in der Nacht zum Samstag..., 2023-07-08 11:17:42+02, 2023-07-08 11:21:11.553489+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/brand-eines-autohauses-schaden-in-millionenhoehe', 'publisher_article_id': None, 'title': 'Landau in der Pfalz: Brand eines Autohauses: Schaden in Millionenhöhe', 'plaintext': 'Ein Autohaus im pfälzischen Landau ist in der Nacht zum Samstag in Brand geraten. Dabei sei ein Schaden in Millionenhöhe entstanden, teilte die Poliz ... (526 characters truncated) ... te ein Feuerwehrsprecher. Er empfahl jedoch, Gegenstände im Außenbereich, wie Gartenmöbel, nass abzuwischen.\n\n© dpa-infocom, dpa:230708-99-328726/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 17, 42, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 11, 553489), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689912, 5, null, https://www.zeit.de/news/2023-07/08/brand-eines-autohauses-schad..., null, Landau in der Pfalz: Brand eines Autohauses: Schaden in Millione..., Ein Autohaus im pfälzischen Landau ist in der Nacht zum Samstag..., 2023-07-08 11:17:42+02, 2023-07-08 11:21:11.553489+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 74, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689912, 5, null, https://www.zeit.de/news/2023-07/08/brand-eines-autohauses-schad..., null, Landau in der Pfalz: Brand eines Autohauses: Schaden in Millione..., Ein Autohaus im pfälzischen Landau ist in der Nacht zum Samstag..., 2023-07-08 11:17:42+02, 2023-07-08 11:21:11.553489+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/brand-eines-autohauses-schaden-in-millionenhoehe', 'publisher_article_id': None, 'title': 'Landau in der Pfalz: Brand eines Autohauses: Schaden in Millionenhöhe', 'plaintext': 'Ein Autohaus im pfälzischen Landau ist in der Nacht zum Samstag in Brand geraten. Dabei sei ein Schaden in Millionenhöhe entstanden, teilte die Poliz ... (526 characters truncated) ... te ein Feuerwehrsprecher. Er empfahl jedoch, Gegenstände im Außenbereich, wie Gartenmöbel, nass abzuwischen.\n\n© dpa-infocom, dpa:230708-99-328726/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 17, 42, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 11, 553489), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-07-08 11:21:12,466 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689913, 5, null, https://www.zeit.de/news/2023-07/08/60-menschen-vor-eritrea-fest..., null, Gießen: 60 Menschen vor Eritrea-Festival in Gewahrsam genommen, Die Polizei hat am frühen Samstagmorgen vor Beginn des umstritt..., 2023-07-08 11:16:33+02, 2023-07-08 11:21:12.140043+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/60-menschen-vor-eritrea-festival-in-gewahrsam-genommen', 'publisher_article_id': None, 'title': 'Gießen: 60 Menschen vor Eritrea-Festival in Gewahrsam genommen', 'plaintext': 'Die Polizei hat am frühen Samstagmorgen vor Beginn des umstrittenen Eritrea-Festivals in Gießen rund 60 Menschen in Gewahrsam genommen. Mehrere Perso ... (2236 characters truncated) ... chtsverletzungen begangen haben soll. Zudem sind in dem Land viele Freiheitsrechte weitgehend eingeschränkt.\n\n© dpa-infocom, dpa:230708-99-328719/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 16, 33, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 12, 140043), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689913, 5, null, https://www.zeit.de/news/2023-07/08/60-menschen-vor-eritrea-fest..., null, Gießen: 60 Menschen vor Eritrea-Festival in Gewahrsam genommen, Die Polizei hat am frühen Samstagmorgen vor Beginn des umstritt..., 2023-07-08 11:16:33+02, 2023-07-08 11:21:12.140043+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 74, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689913, 5, null, https://www.zeit.de/news/2023-07/08/60-menschen-vor-eritrea-fest..., null, Gießen: 60 Menschen vor Eritrea-Festival in Gewahrsam genommen, Die Polizei hat am frühen Samstagmorgen vor Beginn des umstritt..., 2023-07-08 11:16:33+02, 2023-07-08 11:21:12.140043+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/60-menschen-vor-eritrea-festival-in-gewahrsam-genommen', 'publisher_article_id': None, 'title': 'Gießen: 60 Menschen vor Eritrea-Festival in Gewahrsam genommen', 'plaintext': 'Die Polizei hat am frühen Samstagmorgen vor Beginn des umstrittenen Eritrea-Festivals in Gießen rund 60 Menschen in Gewahrsam genommen. Mehrere Perso ... (2236 characters truncated) ... chtsverletzungen begangen haben soll. Zudem sind in dem Land viele Freiheitsrechte weitgehend eingeschränkt.\n\n© dpa-infocom, dpa:230708-99-328719/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 16, 33, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 12, 140043), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-07-08 11:21:12,852 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689914, 5, null, https://www.zeit.de/news/2023-07/08/totes-reh-vermutlich-durch-w..., null, Rhein-Neckar-Kreis: Totes Reh: Vermutlich durch wildernden Hund ..., Ein Jäger hat im Rhein-Neckar-Kreis ein totes Reh gefunden, das..., 2023-07-08 11:14:54+02, 2023-07-08 11:21:12.641008+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/totes-reh-vermutlich-durch-wildernden-hund-gerissen', 'publisher_article_id': None, 'title': 'Rhein-Neckar-Kreis: Totes Reh: Vermutlich durch wildernden Hund gerissen', 'plaintext': 'Ein Jäger hat im Rhein-Neckar-Kreis ein totes Reh gefunden, das vermutlich durch einen Hund getötet wurde. Der Mann fand das Tier am Freitagabend auf ... (209 characters truncated) ... tzungen gefunden worden. Die Polizei geht davon aus, dass ein freilaufender Hund das Rehwild jagt und reißt.\n\n© dpa-infocom, dpa:230708-99-328712/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 14, 54, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 12, 641008), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689914, 5, null, https://www.zeit.de/news/2023-07/08/totes-reh-vermutlich-durch-w..., null, Rhein-Neckar-Kreis: Totes Reh: Vermutlich durch wildernden Hund ..., Ein Jäger hat im Rhein-Neckar-Kreis ein totes Reh gefunden, das..., 2023-07-08 11:14:54+02, 2023-07-08 11:21:12.641008+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 74, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689914, 5, null, https://www.zeit.de/news/2023-07/08/totes-reh-vermutlich-durch-w..., null, Rhein-Neckar-Kreis: Totes Reh: Vermutlich durch wildernden Hund ..., Ein Jäger hat im Rhein-Neckar-Kreis ein totes Reh gefunden, das..., 2023-07-08 11:14:54+02, 2023-07-08 11:21:12.641008+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/totes-reh-vermutlich-durch-wildernden-hund-gerissen', 'publisher_article_id': None, 'title': 'Rhein-Neckar-Kreis: Totes Reh: Vermutlich durch wildernden Hund gerissen', 'plaintext': 'Ein Jäger hat im Rhein-Neckar-Kreis ein totes Reh gefunden, das vermutlich durch einen Hund getötet wurde. Der Mann fand das Tier am Freitagabend auf ... (209 characters truncated) ... tzungen gefunden worden. Die Polizei geht davon aus, dass ein freilaufender Hund das Rehwild jagt und reißt.\n\n© dpa-infocom, dpa:230708-99-328712/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 14, 54, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 12, 641008), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-07-08 11:21:13,464 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689915, 5, null, https://www.zeit.de/news/2023-07/08/bis-zu-36-grad-am-sonntag-in..., null, Wetter: Bis zu 36 Grad am Sonntag in Sachsen-Anhalt, Am ersten Hitzewochenende dieses Sommers kommen die Menschen in ..., 2023-07-08 11:14:14+02, 2023-07-08 11:21:13.054146+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/bis-zu-36-grad-am-sonntag-in-sachsen-anhalt', 'publisher_article_id': None, 'title': 'Wetter: Bis zu 36 Grad am Sonntag in Sachsen-Anhalt', 'plaintext': 'Am ersten Hitzewochenende dieses Sommers kommen die Menschen in Sachsen-Anhalt bei bis zu 36 Grad Celsius ordentlich ins schwitzen. Der Wind wehe nur ... (639 characters truncated) ... estellt, in der eine heiße und zunehmend feuchte und damit schwüle Luftmasse nach Deutschland geführt werde.\n\n© dpa-infocom, dpa:230708-99-328697/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 14, 14, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 13, 54146), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689915, 5, null, https://www.zeit.de/news/2023-07/08/bis-zu-36-grad-am-sonntag-in..., null, Wetter: Bis zu 36 Grad am Sonntag in Sachsen-Anhalt, Am ersten Hitzewochenende dieses Sommers kommen die Menschen in ..., 2023-07-08 11:14:14+02, 2023-07-08 11:21:13.054146+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 74, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689915, 5, null, https://www.zeit.de/news/2023-07/08/bis-zu-36-grad-am-sonntag-in..., null, Wetter: Bis zu 36 Grad am Sonntag in Sachsen-Anhalt, Am ersten Hitzewochenende dieses Sommers kommen die Menschen in ..., 2023-07-08 11:14:14+02, 2023-07-08 11:21:13.054146+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/bis-zu-36-grad-am-sonntag-in-sachsen-anhalt', 'publisher_article_id': None, 'title': 'Wetter: Bis zu 36 Grad am Sonntag in Sachsen-Anhalt', 'plaintext': 'Am ersten Hitzewochenende dieses Sommers kommen die Menschen in Sachsen-Anhalt bei bis zu 36 Grad Celsius ordentlich ins schwitzen. Der Wind wehe nur ... (639 characters truncated) ... estellt, in der eine heiße und zunehmend feuchte und damit schwüle Luftmasse nach Deutschland geführt werde.\n\n© dpa-infocom, dpa:230708-99-328697/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 14, 14, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 13, 54146), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-07-08 11:21:14,576 - fundus_crash_www.zeit.de_2023-07-08 - ERROR - (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689916, 5, null, https://www.zeit.de/news/2023-07/08/hitze-am-wochenende-dwd-erwa..., null, Wetter: Hitze am Wochenende: DWD erwartet bis zu 38 Grad am Sonn..., Bei Temperaturen jenseits der 30-Grad-Marke ist am Wochenende in..., 2023-07-08 11:13:41+02, 2023-07-08 11:21:14.152811+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/hitze-am-wochenende-dwd-erwartet-bis-zu-38-grad-am-sonntag', 'publisher_article_id': None, 'title': 'Wetter: Hitze am Wochenende: DWD erwartet bis zu 38 Grad am Sonntag', 'plaintext': 'Bei Temperaturen jenseits der 30-Grad-Marke ist am Wochenende in Baden-Württemberg vielerorts Schwitzen angesagt. Wie der Deutsche Wetterdienst (DWD) ... (1396 characters truncated) ... e gesundheitliche Gefährdung an. Schatten, Sonnencreme und Sonnenbrille seien hier wichtige Schutzmaßnahmen.\n\n© dpa-infocom, dpa:230708-99-328702/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 13, 41, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 14, 152811), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.NotNullViolation: null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689916, 5, null, https://www.zeit.de/news/2023-07/08/hitze-am-wochenende-dwd-erwa..., null, Wetter: Hitze am Wochenende: DWD erwartet bis zu 38 Grad am Sonn..., Bei Temperaturen jenseits der 30-Grad-Marke ist am Wochenende in..., 2023-07-08 11:13:41+02, 2023-07-08 11:21:14.152811+02, f, f).


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 74, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 115, in insert_into_backend
    backend_session.add(new_article)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 148, in __exit__
    self.rollback()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/util.py", line 144, in __exit__
    self.commit()
  File "<string>", line 2, in commit
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1218, in commit
    self._prepare_impl()
  File "<string>", line 2, in _prepare_impl
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state_changes.py", line 137, in _go
    ret_value = fn(self, *arg, **kw)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 1193, in _prepare_impl
    self.session.flush()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4140, in flush
    self._flush(objects)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4277, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 4237, in _flush
    flush_context.execute()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 467, in execute
    rec.execute(self)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/unitofwork.py", line 644, in execute
    util.preloaded.orm_persistence.save_obj(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 93, in save_obj
    _emit_insert_statements(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/persistence.py", line 1188, in _emit_insert_statements
    result = connection.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1414, in execute
    return meth(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/sql/elements.py", line 485, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1638, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1842, in _execute_context
    return self._exec_single_context(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1983, in _exec_single_context
    self._handle_dbapi_exception(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 2325, in _handle_dbapi_exception
    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1964, in _exec_single_context
    self.dialect.do_execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/default.py", line 747, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.NotNullViolation) null value in column "publisher_article_id" of relation "article" violates not-null constraint
DETAIL:  Failing row contains (689916, 5, null, https://www.zeit.de/news/2023-07/08/hitze-am-wochenende-dwd-erwa..., null, Wetter: Hitze am Wochenende: DWD erwartet bis zu 38 Grad am Sonn..., Bei Temperaturen jenseits der 30-Grad-Marke ist am Wochenende in..., 2023-07-08 11:13:41+02, 2023-07-08 11:21:14.152811+02, f, f).

[SQL: INSERT INTO article (publisher_id, category_id, url, publisher_article_id, title, plaintext, publishing_time, crawl_time, url_deprecated, quotes_extracted) VALUES (%(publisher_id)s, %(category_id)s, %(url)s, %(publisher_article_id)s, %(title)s, %(plaintext)s, %(publishing_time)s, %(crawl_time)s, %(url_deprecated)s, %(quotes_extracted)s) RETURNING article.article_id]
[parameters: {'publisher_id': 5, 'category_id': None, 'url': 'https://www.zeit.de/news/2023-07/08/hitze-am-wochenende-dwd-erwartet-bis-zu-38-grad-am-sonntag', 'publisher_article_id': None, 'title': 'Wetter: Hitze am Wochenende: DWD erwartet bis zu 38 Grad am Sonntag', 'plaintext': 'Bei Temperaturen jenseits der 30-Grad-Marke ist am Wochenende in Baden-Württemberg vielerorts Schwitzen angesagt. Wie der Deutsche Wetterdienst (DWD) ... (1396 characters truncated) ... e gesundheitliche Gefährdung an. Schatten, Sonnencreme und Sonnenbrille seien hier wichtige Schutzmaßnahmen.\n\n© dpa-infocom, dpa:230708-99-328702/2', 'publishing_time': datetime.datetime(2023, 7, 8, 11, 13, 41, tzinfo=tzoffset(None, 7200)), 'crawl_time': datetime.datetime(2023, 7, 8, 11, 21, 14, 152811), 'url_deprecated': False, 'quotes_extracted': False}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2023-07-12 09:34:13,484 - crash - ERROR - 'DE' object is not iterable
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 59, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 54, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 28, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 34, in crawl_to_database
    for fundus_publisher in construct_fundus_parser_list():
TypeError: 'DE' object is not iterable
2023-07-12 09:52:46,385 - crash - ERROR - name 'CrawlerConfig' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 59, in <module>
    main()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/main.py", line 54, in main
    active_mode.execute()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 28, in execute
    crawl_to_database()
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 51, in crawl_to_database
    def filter_database_url_wrapper(crawler_config: CrawlerConfig) -> Callable[[str], bool]:
NameError: name 'CrawlerConfig' is not defined
2023-07-12 09:55:04,670 - fundus_crash_www.dw.com_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:04,860 - fundus_crash_www.faz.net_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:05,001 - fundus_crash_www.focus.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:05,856 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:06,007 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:06,174 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:06,498 - fundus_crash_www.orf.at_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:06,817 - fundus_crash_www.stern.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:06,902 - fundus_crash_www.taz.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:07,125 - fundus_crash_www.waz.de_2023-07-12 - ERROR - name 'text' is not defined
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
NameError: name 'text' is not defined
2023-07-12 09:55:25,014 - fundus_crash_www.dw.com_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:25,190 - fundus_crash_www.faz.net_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:25,336 - fundus_crash_www.focus.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:25,616 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:25,766 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:25,950 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:26,260 - fundus_crash_www.orf.at_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:26,448 - fundus_crash_www.stern.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:26,571 - fundus_crash_www.taz.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:26,810 - fundus_crash_www.waz.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:55:27,259 - fundus_crash_www.welt.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 71, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 66, in merged_filter
    database_result= filter_database_url_wrapper(current_config)(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 55, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (crawler_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:03,214 - fundus_crash_www.dw.com_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:03,483 - fundus_crash_www.faz.net_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:03,627 - fundus_crash_www.focus.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:04,461 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:04,610 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:04,767 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:57:58,780 - fundus_crash_www.dw.com_2023-07-12 - ERROR - 'dict' object has no attribute 'publisher_id'
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config.publisher_id)).all()
AttributeError: 'dict' object has no attribute 'publisher_id'
2023-07-12 09:59:58,047 - fundus_crash_www.dw.com_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 09:59:58,216 - fundus_crash_www.faz.net_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 09:59:58,353 - fundus_crash_www.focus.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 09:59:59,348 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 09:59:59,483 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 09:59:59,640 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 09:59:59,934 - fundus_crash_www.orf.at_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:00,106 - fundus_crash_www.stern.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:00,195 - fundus_crash_www.taz.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:00,406 - fundus_crash_www.waz.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:00,846 - fundus_crash_www.welt.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:20,650 - fundus_crash_www.dw.com_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:20,877 - fundus_crash_www.faz.net_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:21,012 - fundus_crash_www.focus.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:21,276 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:21,419 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:21,589 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:21,889 - fundus_crash_www.orf.at_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:22,070 - fundus_crash_www.stern.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:22,154 - fundus_crash_www.taz.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:22,370 - fundus_crash_www.waz.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [current_config["publisher_id"]]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:40,939 - fundus_crash_www.dw.com_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:41,118 - fundus_crash_www.faz.net_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:41,273 - fundus_crash_www.focus.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:42,266 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:42,421 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:42,591 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:42,913 - fundus_crash_www.orf.at_2023-07-12 - ERROR - List argument must consist only of tuples or dictionaries
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), [(current_config["publisher_id"])]).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 26, in sqlalchemy.cyextension.util._distill_params_20
  File "lib/sqlalchemy/cyextension/util.pyx", line 17, in sqlalchemy.cyextension.util._check_item
sqlalchemy.exc.ArgumentError: List argument must consist only of tuples or dictionaries
2023-07-12 10:00:54,390 - fundus_crash_www.dw.com_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:54,605 - fundus_crash_www.faz.net_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:54,759 - fundus_crash_www.focus.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:55,115 - fundus_crash_www.merkur.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:55,277 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:55,492 - fundus_crash_www.ntv.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:55,796 - fundus_crash_www.orf.at_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:56,017 - fundus_crash_www.stern.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:56,111 - fundus_crash_www.taz.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:56,363 - fundus_crash_www.waz.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:00:56,845 - fundus_crash_www.welt.de_2023-07-12 - ERROR - mapping or list expected for parameters
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 70, in crawl_to_database
    for article in current_fundus_crawler.crawl(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 145, in run
    yield from gen
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/pipeline.py", line 119, in article_gen
    batch: Optional[Iterable[Optional[Article]]] = event_loop.run_until_complete(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 47, in batched_interleave_longest
    result = await coro
  File "/home/aaron/.conda/envs/qse/lib/python3.9/asyncio/tasks.py", line 611, in _wait_for_one
    return f.result()  # May raise f.exception().
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/utils/more_async.py", line 28, in async_next
    return await task
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/scraper.py", line 46, in scrape
    async for html in html_source.fetch():
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 204, in fetch
    if self._filter(url):
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in _filter
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/fundus/scraping/html.py", line 196, in <genexpr>
    return any(url_filter(url) for url_filter in self.url_filter)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 65, in merged_filter
    database_result= filter_database_url_wrapper()(url)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 54, in filter_database_url_wrapper
    current_urls = backend_session.execute(text('Select url from article where publisher_id = ?'), (current_config["publisher_id"])).all()
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2229, in execute
    return self._execute_internal(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/session.py", line 2133, in _execute_internal
    result = conn.execute(
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/engine/base.py", line 1408, in execute
    distilled_parameters = _distill_params_20(parameters)
  File "lib/sqlalchemy/cyextension/util.pyx", line 31, in sqlalchemy.cyextension.util._distill_params_20
sqlalchemy.exc.ArgumentError: mapping or list expected for parameters
2023-07-12 10:05:53,478 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 90, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-07-12 10:21:51,631 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 89, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-07-12 10:22:04,618 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 89, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-07-12 10:22:13,026 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - The article is missing the publishing time
Traceback (most recent call last):
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/modes/impl/crawl_mode.py", line 89, in crawl_to_database
    insert_raw_article_into_database(
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 139, in insert_raw_article_into_database
    insert_into_backend(backend_session=backend_session, raw_article=raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 114, in insert_into_backend
    new_article: Article = construct_backend_article_from_raw(backend_session, raw_article)
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/utils/database.py", line 28, in construct_backend_article_from_raw
    new_article: Article = Article(
  File "<string>", line 4, in __init__
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 576, in _initialize_instance
    manager.dispatch.init_failure(self, args, kwargs)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/util/langhelpers.py", line 147, in __exit__
    raise exc_value.with_traceback(exc_tb)
  File "/home/aaron/.conda/envs/qse/lib/python3.9/site-packages/sqlalchemy/orm/state.py", line 573, in _initialize_instance
    manager.original_init(*mixed[1:], **kwargs)
  File "<string>", line 17, in __init__
  File "/home/aaron/Code/Python/Zitatsuchmaschine/src/database/backend_db/orm_classes.py", line 73, in __post_init__
    raise ValueError("The article is missing the publishing time")
ValueError: The article is missing the publishing time
2023-07-12 10:23:00,473 - fundus_crash_www.ndr.de_2023-07-12 - ERROR - Invalid control character at: line 6 column 239 (char 362)
NoneType: None
